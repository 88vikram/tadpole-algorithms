{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 1;\n",
       "            var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 2;\n",
       "            var nbb_formatted_code = \"import argparse\\nimport os\\nimport sys\\nfrom socket import gethostname\\nimport time\\nimport datetime\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from socket import gethostname\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 3;\n",
       "            var nbb_formatted_code = \"parser = argparse.ArgumentParser(\\n    description=\\\"Launches clustering model on \\\"\\n    \\\"using cortical thickness maps derived from MRI\\\"\\n)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Launches clustering model on \"\n",
    "    \"using cortical thickness maps derived from MRI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 4;\n",
       "            var nbb_formatted_code = \"args = {\\n    \\\"runIndex\\\": 1,\\n    \\\"nrProc\\\": 1,\\n    \\\"models\\\": 13,\\n    \\\"nrOuterIt\\\": 5,\\n    \\\"nrInnerIt\\\": 1,\\n    \\\"nrClust\\\": 12,\\n    \\\"initClustering\\\": \\\"k-means\\\",\\n    \\\"rangeFactor\\\": 1,\\n    \\\"informPrior\\\": 0,\\n    \\\"leaderboard\\\": 1,\\n    \\\"agg\\\": 1,\\n    \\\"cluster\\\": False,\\n    \\\"reduceSpace\\\": 1,\\n    \\\"alphaMRF\\\": 1,\\n    \\\"d3\\\": 0,\\n    \\\"stdBeta\\\": 0.1,\\n    \\\"stdGammaAlpha\\\": 0.0025,\\n}\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = {\n",
    "    \"runIndex\": 1,\n",
    "    \"nrProc\": 1,\n",
    "    \"models\": 13,\n",
    "    \"nrOuterIt\": 5,\n",
    "    \"nrInnerIt\": 1,\n",
    "    \"nrClust\": 12,\n",
    "    \"initClustering\": \"k-means\",\n",
    "    \"rangeFactor\": 1,\n",
    "    \"informPrior\": 0,\n",
    "    \"leaderboard\": 1,\n",
    "    \"agg\": 1,\n",
    "    \"cluster\": False,\n",
    "    \"reduceSpace\": 1,\n",
    "    \"alphaMRF\": 1,\n",
    "    \"d3\": 0,\n",
    "    \"stdBeta\": 0.1,\n",
    "    \"stdGammaAlpha\": 0.0025,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 5;\n",
       "            var nbb_formatted_code = \"# don't import matplotlib until here, add other imports below\\nif args.get(\\\"agg\\\"):\\n    # print(matplotlib.__version__)\\n    import matplotlib\\n\\n    # print(matplotlib.get_backend())\\n    matplotlib.use(\\\"Agg\\\")\\n    # print(matplotlib.get_backend())\\n    # print(asds)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# don't import matplotlib until here, add other imports below\n",
    "if args.get(\"agg\"):\n",
    "    # print(matplotlib.__version__)\n",
    "    import matplotlib\n",
    "\n",
    "    # print(matplotlib.get_backend())\n",
    "    matplotlib.use(\"Agg\")\n",
    "    # print(matplotlib.get_backend())\n",
    "    # print(asds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 6;\n",
       "            var nbb_formatted_code = \"from voxCommon import initCommonVoxParams\\nimport evaluationFramework\\nfrom voxelDPM import *\\nfrom aux import *\\nfrom adniCommon import *\\nfrom env import *\\nimport pandas as pd\\nimport PlotterVDPM\\nimport VDPMNan\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from voxCommon import initCommonVoxParams\n",
    "import evaluationFramework\n",
    "from voxelDPM import *\n",
    "from aux import *\n",
    "from adniCommon import *\n",
    "from env import *\n",
    "import pandas as pd\n",
    "import PlotterVDPM\n",
    "import VDPMNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 7;\n",
       "            var nbb_formatted_code = \"params, plotTrajParams = initCommonVoxParams(args)\\nplotTrajParams[\\\"legendCols\\\"] = 4\\nplotTrajParams[\\\"diagColors\\\"] = {CTL: \\\"b\\\", MCI: \\\"g\\\", AD: \\\"r\\\", -1: \\\"y\\\"}\\nplotTrajParams[\\\"diagLabels\\\"] = {CTL: \\\"CTL\\\", MCI: \\\"MCI\\\", AD: \\\"AD\\\", -1: \\\"N/A\\\"}\\nplotTrajParams[\\\"ylimitsRandPoints\\\"] = (-5, 5)\\nplotTrajParams[\\\"diagNrs\\\"] = [CTL, MCI, AD]\\n\\nplotTrajParams[\\\"SubfigClustMaxWinSize\\\"] = (\\n    1300,\\n    plotTrajParams[\\\"SubfigClustMaxWinSize\\\"][1],\\n)\\nplotTrajParams[\\\"Clust3DMaxWinSize\\\"] = (900, 600)\\n# plotTrajParams['ylimTrajWeightedDataMean'] = (-3,2)\\nplotTrajParams[\\\"ylimTrajSamplesInOneNoData\\\"] = (-2.5, 1.5)\\nplotTrajParams[\\\"biomkAxisLabel\\\"] = \\\"Cortical Thickness Z-score\\\"\\nplotTrajParams[\\\"biomkWasInversed\\\"] = False\\n\\nrefDate = datetime.date(2000, 1, 1)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params, plotTrajParams = initCommonVoxParams(args)\n",
    "plotTrajParams[\"legendCols\"] = 4\n",
    "plotTrajParams[\"diagColors\"] = {CTL: \"b\", MCI: \"g\", AD: \"r\", -1: \"y\"}\n",
    "plotTrajParams[\"diagLabels\"] = {CTL: \"CTL\", MCI: \"MCI\", AD: \"AD\", -1: \"N/A\"}\n",
    "plotTrajParams[\"ylimitsRandPoints\"] = (-5, 5)\n",
    "plotTrajParams[\"diagNrs\"] = [CTL, MCI, AD]\n",
    "\n",
    "plotTrajParams[\"SubfigClustMaxWinSize\"] = (\n",
    "    1300,\n",
    "    plotTrajParams[\"SubfigClustMaxWinSize\"][1],\n",
    ")\n",
    "plotTrajParams[\"Clust3DMaxWinSize\"] = (900, 600)\n",
    "# plotTrajParams['ylimTrajWeightedDataMean'] = (-3,2)\n",
    "plotTrajParams[\"ylimTrajSamplesInOneNoData\"] = (-2.5, 1.5)\n",
    "plotTrajParams[\"biomkAxisLabel\"] = \"Cortical Thickness Z-score\"\n",
    "plotTrajParams[\"biomkWasInversed\"] = False\n",
    "\n",
    "refDate = datetime.date(2000, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 8;\n",
       "            var nbb_formatted_code = \"def cleanTadpoleData(df):\\n\\n    df.loc[df.RAVLT_learning < 0, \\\"RAVLT_learning\\\"] = np.nan\\n    df.loc[df.RAVLT_forgetting < 0, \\\"RAVLT_forgetting\\\"] = np.nan\\n    df.loc[df.RAVLT_perc_forgetting < 0, \\\"RAVLT_perc_forgetting\\\"] = np.nan\\n\\n    petCols = list(\\n        df.loc[:, \\\"HIPPL01_BAIPETNMRC_09_12_16\\\":\\\"MCSUVRCERE_BAIPETNMRC_09_12_16\\\"]\\n    )\\n    # df[petCols].replace({'-4': np.nan, -4: np.nan}, inplace=True)\\n    for c in petCols:\\n        df.loc[df[c] == \\\"-4\\\", c] = np.nan\\n\\n    return df\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cleanTadpoleData(df):\n",
    "\n",
    "    df.loc[df.RAVLT_learning < 0, \"RAVLT_learning\"] = np.nan\n",
    "    df.loc[df.RAVLT_forgetting < 0, \"RAVLT_forgetting\"] = np.nan\n",
    "    df.loc[df.RAVLT_perc_forgetting < 0, \"RAVLT_perc_forgetting\"] = np.nan\n",
    "\n",
    "    petCols = list(\n",
    "        df.loc[:, \"HIPPL01_BAIPETNMRC_09_12_16\":\"MCSUVRCERE_BAIPETNMRC_09_12_16\"]\n",
    "    )\n",
    "    # df[petCols].replace({'-4': np.nan, -4: np.nan}, inplace=True)\n",
    "    for c in petCols:\n",
    "        df.loc[df[c] == \"-4\", c] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 9;\n",
       "            var nbb_formatted_code = \"def dateDiffToMonths(diff):\\n    return diff.days / (365.0 / 12)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dateDiffToMonths(diff):\n",
    "    return diff.days / (365.0 / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 10;\n",
       "            var nbb_formatted_code = \"def parseTadpoleData(df):\\n\\n    cols = (\\n        list(df.loc[:, \\\"FDG\\\":\\\"EcogSPTotal\\\"])\\n        + list(df.loc[:, \\\"Ventricles\\\":\\\"MidTemp\\\"])\\n        + list(\\n            df.loc[\\n                :,\\n                \\\"ST101SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16\\\":\\\"ST9SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16\\\",\\n            ]\\n        )\\n        + list(\\n            df.loc[\\n                :,\\n                \\\"ST101SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\\\":\\\"ST9SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\\\",\\n            ]\\n        )\\n        + list(\\n            df.loc[:, \\\"HIPPL01_BAIPETNMRC_09_12_16\\\":\\\"MCSUVRCERE_BAIPETNMRC_09_12_16\\\"]\\n        )\\n        + list(\\n            df.loc[\\n                :,\\n                \\\"CEREBELLUMGREYMATTER_UCBERKELEYAV45_10_17_16\\\":\\\"WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV45_10_17_16\\\",\\n            ]\\n        )\\n        + list(\\n            df.loc[\\n                :,\\n                \\\"CEREBELLUMGREYMATTER_UCBERKELEYAV1451_10_17_16\\\":\\\"WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV1451_10_17_16\\\",\\n            ]\\n        )\\n        + list(df.loc[:, \\\"FA_CST_L_DTIROI_04_30_14\\\":\\\"AD_SUMFX_DTIROI_04_30_14\\\"])\\n        + list(df.loc[:, \\\"ABETA_UPENNBIOMK9_04_19_17\\\":\\\"PTAU_UPENNBIOMK9_04_19_17\\\"])\\n    )\\n\\n    # TODO: re-process data more, continue form here: change AV45 -> AV45/SIZE of ROI\\n    # print('cols', cols)\\n    # filter out the FS cols with Standard deviation of volumes, cort thickness, etc ... Only keep average\\n    colsFilt = []\\n    for col in cols:\\n        if col[:2] == \\\"ST\\\" and (col[5] == \\\"S\\\" or col[6] == \\\"S\\\"):\\n            continue\\n\\n        colsFilt += [col]\\n\\n    # print(ads)\\n    # print(df.D1)\\n    # print(df.shape)\\n    d2Ind = df.RID[df.loc[:, \\\"D2\\\"] == 1].to_numpy()\\n\\n    # print('d2Ind', np.unique(d2Ind), np.unique(d2Ind).shape)\\n\\n    df[cols] = df[cols].apply(pd.to_numeric, errors=\\\"coerce\\\", axis=1)\\n    pickle.dump(\\n        dict(df=df),\\n        open(\\\"data/tadpoleCleanDf.npz\\\", \\\"wb\\\"),\\n        protocol=pickle.HIGHEST_PROTOCOL,\\n    )\\n    df = pickle.load(open(\\\"data/tadpoleCleanDf.npz\\\", \\\"rb\\\"))[\\\"df\\\"]\\n\\n    # normalise ventricles by ICV\\n    df[\\\"Ventricles\\\"] = df[\\\"Ventricles\\\"] / df[\\\"ICV\\\"]\\n\\n    # data = df.as_matrix(columns=cols)\\n    data = df[cols].to_numpy()\\n\\n    # convert diagnoses such as 'MCI to Dementia' to 'Dementia', etc ...\\n    # ctlDxchange = [1, 7, 9] mciDxchange = [2, 4, 8] adDxChange = [3, 5, 6]\\n    mapping = {1: CTL, 7: CTL, 9: CTL, 2: MCI, 4: MCI, 8: MCI, 3: AD, 5: AD, 6: AD}\\n    # df.replace({'DXCHANGE': mapping}, inplace=True)\\n    df[\\\"DXCHANGE\\\"] = df[\\\"DXCHANGE\\\"].map(mapping)\\n    diag = df[\\\"DXCHANGE\\\"].to_numpy()\\n\\n    examDates = df.EXAMDATE.to_numpy()\\n    df[\\\"EXAMDATE\\\"] = pd.to_datetime(df[\\\"EXAMDATE\\\"], format=\\\"%Y-%m-%d\\\")\\n\\n    dataDf = df[cols]\\n    dataDf.to_csv(\\\"output/tadpoleCleanDf.csv\\\")\\n\\n    # build numpy string array\\n    nrCols = len(cols)\\n    labels = np.ndarray((nrCols,), dtype=\\\"S100\\\")\\n    for c in range(nrCols):\\n        labels[c] = cols[c]\\n\\n    partCode = df.RID.to_numpy()\\n    # print('partCode', partCode)\\n    unqPartCode = np.unique(partCode)\\n    nrUnqSubj = len(unqPartCode)\\n\\n    ageAtScan = np.zeros(partCode.shape, np.float)\\n    scanTimepts = np.zeros(partCode.shape, np.float)\\n\\n    for s in range(nrUnqSubj):\\n        subjRowsCurr = df.RID == unqPartCode[s]\\n        ageAtBlCurr = df.AGE[subjRowsCurr]\\n\\n        examDatesCurr = df.EXAMDATE[subjRowsCurr]\\n        minInd = np.argmin(examDatesCurr)\\n        yearsDiffs = [(d - examDatesCurr[minInd]).days / 365 for d in examDatesCurr]\\n\\n        ageAtScan[subjRowsCurr] = ageAtBlCurr + yearsDiffs\\n\\n        scanTimepts[subjRowsCurr] = np.argsort(np.argsort(yearsDiffs))\\n\\n        sortedVisitsCurr = np.argsort(yearsDiffs)\\n        diagCurrSorted = diag[subjRowsCurr][sortedVisitsCurr]\\n\\n        notNanDiags = [d for d in diagCurrSorted if not np.isnan(d)]\\n\\n        diagCurrSortedFilled = np.copy(diagCurrSorted)\\n\\n        if len(notNanDiags) == 0:\\n            # set the subject diag as -1 if there is absolutely no diagnosis\\n            diagCurrSortedFilled[0] = -1\\n        else:\\n            if np.isnan(diagCurrSortedFilled[0]):\\n                diagCurrSortedFilled[0] = notNanDiags[0]\\n\\n            for v in range(1, len(sortedVisitsCurr)):\\n                if np.isnan(diagCurrSortedFilled[v]):\\n                    diagCurrSortedFilled[v] = diagCurrSortedFilled[v - 1]\\n\\n        diagFilledInOrigOrder = diagCurrSortedFilled[np.argsort(sortedVisitsCurr)]\\n\\n        diag[subjRowsCurr] = diagFilledInOrigOrder\\n\\n    # compute number of months since Jan 2000 for each EXAMDATEs\\n    monthsSinceRefTime = np.zeros(partCode.shape, np.float)\\n\\n    for r in range(df.RID.shape[0]):\\n        monthsSinceRefTime[r] = dateDiffToMonths(df.EXAMDATE[r].date() - refDate)\\n\\n    assert not np.isnan(ageAtScan).any()\\n    assert not np.isnan(diag).any()\\n    assert not np.isnan(scanTimepts).any()\\n    assert not np.isnan(partCode).any()\\n    assert not np.isnan(monthsSinceRefTime).any()\\n\\n    return (\\n        data,\\n        diag,\\n        labels,\\n        scanTimepts,\\n        partCode,\\n        ageAtScan,\\n        dataDf,\\n        monthsSinceRefTime,\\n        examDates,\\n        d2Ind,\\n    )\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parseTadpoleData(df):\n",
    "\n",
    "    cols = (\n",
    "        list(df.loc[:, \"FDG\":\"EcogSPTotal\"])\n",
    "        + list(df.loc[:, \"Ventricles\":\"MidTemp\"])\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"ST101SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16\":\"ST9SV_UCSFFSL_02_01_16_UCSFFSL51ALL_08_01_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"ST101SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\":\"ST9SV_UCSFFSX_11_02_15_UCSFFSX51_08_01_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[:, \"HIPPL01_BAIPETNMRC_09_12_16\":\"MCSUVRCERE_BAIPETNMRC_09_12_16\"]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"CEREBELLUMGREYMATTER_UCBERKELEYAV45_10_17_16\":\"WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV45_10_17_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(\n",
    "            df.loc[\n",
    "                :,\n",
    "                \"CEREBELLUMGREYMATTER_UCBERKELEYAV1451_10_17_16\":\"WM_HYPOINTENSITIES_SIZE_UCBERKELEYAV1451_10_17_16\",\n",
    "            ]\n",
    "        )\n",
    "        + list(df.loc[:, \"FA_CST_L_DTIROI_04_30_14\":\"AD_SUMFX_DTIROI_04_30_14\"])\n",
    "        + list(df.loc[:, \"ABETA_UPENNBIOMK9_04_19_17\":\"PTAU_UPENNBIOMK9_04_19_17\"])\n",
    "    )\n",
    "\n",
    "    # TODO: re-process data more, continue form here: change AV45 -> AV45/SIZE of ROI\n",
    "    # print('cols', cols)\n",
    "    # filter out the FS cols with Standard deviation of volumes, cort thickness, etc ... Only keep average\n",
    "    colsFilt = []\n",
    "    for col in cols:\n",
    "        if col[:2] == \"ST\" and (col[5] == \"S\" or col[6] == \"S\"):\n",
    "            continue\n",
    "\n",
    "        colsFilt += [col]\n",
    "\n",
    "    # print(ads)\n",
    "    # print(df.D1)\n",
    "    # print(df.shape)\n",
    "    d2Ind = df.RID[df.loc[:, \"D2\"] == 1].to_numpy()\n",
    "\n",
    "    # print('d2Ind', np.unique(d2Ind), np.unique(d2Ind).shape)\n",
    "\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors=\"coerce\", axis=1)\n",
    "    pickle.dump(\n",
    "        dict(df=df),\n",
    "        open(\"data/tadpoleCleanDf.npz\", \"wb\"),\n",
    "        protocol=pickle.HIGHEST_PROTOCOL,\n",
    "    )\n",
    "    df = pickle.load(open(\"data/tadpoleCleanDf.npz\", \"rb\"))[\"df\"]\n",
    "\n",
    "    # normalise ventricles by ICV\n",
    "    df[\"Ventricles\"] = df[\"Ventricles\"] / df[\"ICV\"]\n",
    "\n",
    "    # data = df.as_matrix(columns=cols)\n",
    "    data = df[cols].to_numpy()\n",
    "\n",
    "    # convert diagnoses such as 'MCI to Dementia' to 'Dementia', etc ...\n",
    "    # ctlDxchange = [1, 7, 9] mciDxchange = [2, 4, 8] adDxChange = [3, 5, 6]\n",
    "    mapping = {1: CTL, 7: CTL, 9: CTL, 2: MCI, 4: MCI, 8: MCI, 3: AD, 5: AD, 6: AD}\n",
    "    # df.replace({'DXCHANGE': mapping}, inplace=True)\n",
    "    df[\"DXCHANGE\"] = df[\"DXCHANGE\"].map(mapping)\n",
    "    diag = df[\"DXCHANGE\"].to_numpy()\n",
    "\n",
    "    examDates = df.EXAMDATE.to_numpy()\n",
    "    df[\"EXAMDATE\"] = pd.to_datetime(df[\"EXAMDATE\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    dataDf = df[cols]\n",
    "    dataDf.to_csv(\"output/tadpoleCleanDf.csv\")\n",
    "\n",
    "    # build numpy string array\n",
    "    nrCols = len(cols)\n",
    "    labels = np.ndarray((nrCols,), dtype=\"S100\")\n",
    "    for c in range(nrCols):\n",
    "        labels[c] = cols[c]\n",
    "\n",
    "    partCode = df.RID.to_numpy()\n",
    "    # print('partCode', partCode)\n",
    "    unqPartCode = np.unique(partCode)\n",
    "    nrUnqSubj = len(unqPartCode)\n",
    "\n",
    "    ageAtScan = np.zeros(partCode.shape, np.float)\n",
    "    scanTimepts = np.zeros(partCode.shape, np.float)\n",
    "\n",
    "    for s in range(nrUnqSubj):\n",
    "        subjRowsCurr = df.RID == unqPartCode[s]\n",
    "        ageAtBlCurr = df.AGE[subjRowsCurr]\n",
    "\n",
    "        examDatesCurr = df.EXAMDATE[subjRowsCurr]\n",
    "        minInd = np.argmin(examDatesCurr)\n",
    "        yearsDiffs = [(d - examDatesCurr[minInd]).days / 365 for d in examDatesCurr]\n",
    "\n",
    "        ageAtScan[subjRowsCurr] = ageAtBlCurr + yearsDiffs\n",
    "\n",
    "        scanTimepts[subjRowsCurr] = np.argsort(np.argsort(yearsDiffs))\n",
    "\n",
    "        sortedVisitsCurr = np.argsort(yearsDiffs)\n",
    "        diagCurrSorted = diag[subjRowsCurr][sortedVisitsCurr]\n",
    "\n",
    "        notNanDiags = [d for d in diagCurrSorted if not np.isnan(d)]\n",
    "\n",
    "        diagCurrSortedFilled = np.copy(diagCurrSorted)\n",
    "\n",
    "        if len(notNanDiags) == 0:\n",
    "            # set the subject diag as -1 if there is absolutely no diagnosis\n",
    "            diagCurrSortedFilled[0] = -1\n",
    "        else:\n",
    "            if np.isnan(diagCurrSortedFilled[0]):\n",
    "                diagCurrSortedFilled[0] = notNanDiags[0]\n",
    "\n",
    "            for v in range(1, len(sortedVisitsCurr)):\n",
    "                if np.isnan(diagCurrSortedFilled[v]):\n",
    "                    diagCurrSortedFilled[v] = diagCurrSortedFilled[v - 1]\n",
    "\n",
    "        diagFilledInOrigOrder = diagCurrSortedFilled[np.argsort(sortedVisitsCurr)]\n",
    "\n",
    "        diag[subjRowsCurr] = diagFilledInOrigOrder\n",
    "\n",
    "    # compute number of months since Jan 2000 for each EXAMDATEs\n",
    "    monthsSinceRefTime = np.zeros(partCode.shape, np.float)\n",
    "\n",
    "    for r in range(df.RID.shape[0]):\n",
    "        monthsSinceRefTime[r] = dateDiffToMonths(df.EXAMDATE[r].date() - refDate)\n",
    "\n",
    "    assert not np.isnan(ageAtScan).any()\n",
    "    assert not np.isnan(diag).any()\n",
    "    assert not np.isnan(scanTimepts).any()\n",
    "    assert not np.isnan(partCode).any()\n",
    "    assert not np.isnan(monthsSinceRefTime).any()\n",
    "\n",
    "    return (\n",
    "        data,\n",
    "        diag,\n",
    "        labels,\n",
    "        scanTimepts,\n",
    "        partCode,\n",
    "        ageAtScan,\n",
    "        dataDf,\n",
    "        monthsSinceRefTime,\n",
    "        examDates,\n",
    "        d2Ind,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 11;\n",
       "            var nbb_formatted_code = \"def makeBiomksDecr(data, diag, labels):\\n\\n    assert data.shape[0] == diag.shape[0]\\n\\n    # perform t-test on every voxel, sort them by p-values\\n    pVals = scipy.stats.ttest_ind(\\n        data[diag == CTL, :], data[diag == AD, :], nan_policy=\\\"omit\\\"\\n    )[1]\\n\\n    sortedInd = np.argsort(pVals)\\n    # print('sortedInd', sortedInd)\\n\\n    # print('data[diag == CTL, :]', data[diag == CTL, :])\\n    meanCTL = np.nanmean(data[diag == CTL, :], axis=0)\\n    meanAD = np.nanmean(data[diag == AD, :], axis=0)\\n    stdCTL = np.nanstd(data[diag == CTL, :], axis=0)\\n    stdAD = np.nanstd(data[diag == AD, :], axis=0)\\n\\n    # record which biomarkers have had their sign flipped. Multiply this vector\\n    # with the scale from the normalisation with controls that we did earlier.\\n    biomkScaleExtra = np.ones(pVals.shape)\\n\\n    for b in sortedInd:\\n\\n        if (pVals[b] < 0.001) and meanAD[b] > meanCTL[b]:\\n            data[:, b] = data[:, b] * (-1)\\n            biomkScaleExtra[b] = -1\\n    # print('flipped sign for %s' % labels[b])\\n\\n    return data, sortedInd, biomkScaleExtra, pVals\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def makeBiomksDecr(data, diag, labels):\n",
    "\n",
    "    assert data.shape[0] == diag.shape[0]\n",
    "\n",
    "    # perform t-test on every voxel, sort them by p-values\n",
    "    pVals = scipy.stats.ttest_ind(\n",
    "        data[diag == CTL, :], data[diag == AD, :], nan_policy=\"omit\"\n",
    "    )[1]\n",
    "\n",
    "    sortedInd = np.argsort(pVals)\n",
    "    # print('sortedInd', sortedInd)\n",
    "\n",
    "    # print('data[diag == CTL, :]', data[diag == CTL, :])\n",
    "    meanCTL = np.nanmean(data[diag == CTL, :], axis=0)\n",
    "    meanAD = np.nanmean(data[diag == AD, :], axis=0)\n",
    "    stdCTL = np.nanstd(data[diag == CTL, :], axis=0)\n",
    "    stdAD = np.nanstd(data[diag == AD, :], axis=0)\n",
    "\n",
    "    # record which biomarkers have had their sign flipped. Multiply this vector\n",
    "    # with the scale from the normalisation with controls that we did earlier.\n",
    "    biomkScaleExtra = np.ones(pVals.shape)\n",
    "\n",
    "    for b in sortedInd:\n",
    "\n",
    "        if (pVals[b] < 0.001) and meanAD[b] > meanCTL[b]:\n",
    "            data[:, b] = data[:, b] * (-1)\n",
    "            biomkScaleExtra[b] = -1\n",
    "    # print('flipped sign for %s' % labels[b])\n",
    "\n",
    "    return data, sortedInd, biomkScaleExtra, pVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 12;\n",
       "            var nbb_formatted_code = \"def launchTadpole(runIndex, nrProcesses, modelToRun):\\n\\n    genProcessedDataset = 1\\n\\n    if genProcessedDataset:\\n        if args.get(\\\"leaderboard\\\") == 0:\\n            inputFileData = \\\"data/TADPOLE_D1_D2.csv\\\"\\n            sys.stdout.flush()\\n            outFileCheckpoint2 = \\\"output/tadpoleDf2.npz\\\"\\n            # print('loading data file')\\n            df = pd.read_csv(inputFileData, low_memory=False)\\n            df = cleanTadpoleData(df)\\n            data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, examDates, predInd = parseTadpoleData(\\n                df\\n            )\\n\\n        else:\\n            outFileCheckpoint2 = \\\"output/tadpoleDf2Ldb.npz\\\"\\n            # print('loading data file')\\n            inputFileDataD1D2 = \\\"data/TADPOLE_D1_D2.csv\\\"\\n            df = pd.read_csv(inputFileDataD1D2, low_memory=False)\\n            df = cleanTadpoleData(df)\\n            inputFileDataLB = \\\"data/TADPOLE_LB1_LB2.csv\\\"\\n            dfLB = pd.read_csv(inputFileDataLB, low_memory=False)\\n\\n            # this function runs exactly as in the normal submission, no difference here for leaderboard\\n            data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, examDates, _ = parseTadpoleData(\\n                df\\n            )\\n\\n            filterMaskLB12 = np.logical_or(dfLB.LB1 == 1, dfLB.LB2 == 1)\\n            assert data.shape[0] == dfLB.shape[0]\\n\\n            # print(np.sum(filterMaskLB12), filterMaskLB12.shape[0])\\n            # print(dads)\\n\\n            data = data[filterMaskLB12, :]\\n            diag = diag[filterMaskLB12]\\n            scanTimepts = scanTimepts[filterMaskLB12]\\n            partCode = partCode[filterMaskLB12]\\n            ageAtScan = ageAtScan[filterMaskLB12]\\n            dataDf = dataDf[filterMaskLB12]\\n            dataDf.reset_index(drop=True, inplace=True)\\n            dataDf.reindex(index=range(dataDf.shape[0]))\\n            monthsSinceRefTime = monthsSinceRefTime[filterMaskLB12]\\n            examDates = examDates[filterMaskLB12]\\n            predInd = dfLB.RID[dfLB.LB2 == 1].to_numpy()\\n\\n        dataStruct = dict(\\n            data=data,\\n            diag=diag,\\n            labels=labels,\\n            scanTimepts=scanTimepts,\\n            partCode=partCode,\\n            ageAtScan=ageAtScan,\\n            dataDf=dataDf,\\n            monthsSinceRefTime=monthsSinceRefTime,\\n            examDates=examDates,\\n            predInd=predInd,\\n        )\\n        pickle.dump(\\n            dataStruct, open(outFileCheckpoint2, \\\"wb\\\"), protocol=pickle.HIGHEST_PROTOCOL\\n        )\\n\\n    else:\\n        if args.get(\\\"leaderboard\\\") == 0:\\n            outFileCheckpoint2 = \\\"output/tadpoleDf2.npz\\\"\\n        else:\\n            outFileCheckpoint2 = \\\"output/tadpoleDf2Ldb.npz\\\"\\n\\n    dataStruct = pickle.load(open(outFileCheckpoint2, \\\"rb\\\"))\\n    data = dataStruct[\\\"data\\\"]\\n    diag = dataStruct[\\\"diag\\\"]\\n    labels = dataStruct[\\\"labels\\\"]\\n    scanTimepts = dataStruct[\\\"scanTimepts\\\"]\\n    partCode = dataStruct[\\\"partCode\\\"]\\n    ageAtScan = dataStruct[\\\"ageAtScan\\\"]\\n    # dataDf = dataStruct['dataDf']\\n    monthsSinceRefTime = dataStruct[\\\"monthsSinceRefTime\\\"]\\n    examDates = dataStruct[\\\"examDates\\\"]\\n    predInd = dataStruct[\\\"predInd\\\"]\\n\\n    # filter AD subjects\\n    # diagInd = np.array(np.where(matData['diag'] == PCA)[0])\\n    ##print('compiling parameters')\\n    sys.stdout.flush()\\n\\n    ##print('diag', np.unique(diag), diag)\\n    # print(adsas)\\n\\n    unqPartCode = np.unique(partCode)\\n    nrUnqPart = len(unqPartCode)\\n\\n    # calculate Z-scores at each point w.r.t controls at baseline\\n    # controlBlInd = np.logical_and(diag == CTL, scanTimepts == 1)\\n    controlInd = diag == CTL\\n    stdBiomk = np.nanstd(data[diag == CTL], 0)\\n    biomkMaskCTL = np.isnan(np.nanstd(data[diag == CTL], 0))\\n    biomkMaskAD = np.isnan(np.nanstd(data[diag == AD], 0))\\n    biomkMaskMCI = np.isnan(np.nanstd(data[diag == MCI], 0))\\n    mask = np.logical_or(np.logical_or(biomkMaskCTL, biomkMaskMCI), biomkMaskAD)\\n    # print(ads)\\n    selectedBiomk = np.logical_not(np.logical_or(mask, stdBiomk == 0))\\n\\n    ##print(data.shape)\\n    data = data[:, selectedBiomk]\\n    labels = labels[selectedBiomk]\\n    pointIndices = np.array(range(data.shape[1]))\\n    stdBiomk = np.nanstd(data[controlInd], 0)\\n    ##print(data.shape)\\n    # print(ads)\\n\\n    meanCTL = np.nanmean(data[controlInd], 0)  # calculate Z-scores\\n    stdCTL = np.nanstd(data[controlInd], 0)\\n    dataZ = (data - meanCTL[None, :]) / stdCTL[None, :]\\n    data = dataZ\\n\\n    outlierRows, outlierCols = np.where(np.abs(dataZ) > 50)\\n    filterMask = np.ones(data.shape[0], bool)\\n    filterMask[outlierRows] = 0\\n    data = data[filterMask]\\n    diag = diag[filterMask]\\n    scanTimepts = scanTimepts[filterMask]\\n    partCode = partCode[filterMask]\\n    ageAtScan = ageAtScan[filterMask]\\n    monthsSinceRefTime = monthsSinceRefTime[filterMask]\\n    examDates = examDates[filterMask]\\n    meanAgeAtScan = np.mean(ageAtScan.astype(float))\\n    ageAtScanCentered = (ageAtScan - meanAgeAtScan).astype(np.float16)\\n\\n    nrSubj, nrBiomk = data.shape\\n    # print('nrBiomk', nrBiomk)\\n    # print(adsa)\\n\\n    dataAD = data[diag == AD, :]\\n\\n    # make all biomarkers decreasing by flipping their signs if necessary\\n    # also perform a t-test to see which ones are most informative, sort them by pvalue (i.e. sortedByPvalInd)\\n    # the new data is re-scaled\\n    data, sortedByPvalInd, biomkScaleExtra, pVals = makeBiomksDecr(data, diag, labels)\\n    # doTtest(data, diag, pointIndices)\\n\\n    # multiply the scaling we did from controls with (-1) if the biomk had the sign flipped\\n    stdBiomkRescale = biomkScaleExtra * stdCTL\\n\\n    assert sortedByPvalInd.shape[0] == data.shape[1]\\n\\n    sys.stdout.flush()\\n\\n    global params\\n\\n    params[\\\"data\\\"] = data\\n    params[\\\"diag\\\"] = diag\\n    params[\\\"scanTimepts\\\"] = scanTimepts\\n    params[\\\"partCode\\\"] = partCode\\n    params[\\\"ageAtScan\\\"] = ageAtScan\\n    params[\\n        \\\"initShift\\\"\\n    ] = ageAtScanCentered  # initialise time shifts (betas) to (age - meanAge)\\n    params[\\\"biomkDir\\\"] = DECR\\n    params[\\\"modelToRun\\\"] = modelToRun\\n    params[\\\"datasetFull\\\"] = \\\"tadpole\\\"\\n    params[\\\"labels\\\"] = labels\\n    params[\\\"predInd\\\"] = predInd\\n    params[\\\"examDates\\\"] = examDates\\n\\n    # print('ageAtScanCentered', ageAtScanCentered)\\n    # print('ageAtScan', ageAtScan)\\n    # print('scanTimepts', scanTimepts)\\n    # ada\\n\\n    ## print('outFileCheckpoint2', outFileCheckpoint2)\\n    ## print('d2Ind', np.unique(predInd), np.unique(predInd).shape)\\n    # print(adsa)\\n\\n    # filter down to 100 subjects to make it run faster, just for testing. Also select only some biomarkers\\n    unqPartCode = np.unique(params[\\\"partCode\\\"])\\n    nrPartToSample = 30\\n    np.random.seed(3)\\n    selectedPartCode = np.random.choice(unqPartCode, nrPartToSample)\\n    dataIndices = np.in1d(params[\\\"partCode\\\"], selectedPartCode)\\n    # params = filterDDSPAIndices(params, dataIndices)\\n\\n    indices = [\\n        i\\n        for i in range(len(labels))\\n        if labels[i]\\n        in [\\n            b\\\"FDG\\\",\\n            b\\\"AV45\\\",\\n            b\\\"CDRSB\\\",\\n            b\\\"ADAS13\\\",\\n            b\\\"Ventricles\\\",\\n            b\\\"Hippocampus\\\",\\n            b\\\"WholeBrain\\\",\\n            b\\\"Entorhinal\\\",\\n            b\\\"MidTemp\\\",\\n            b\\\"ABETA_UPENNBIOMK9_04_19_17\\\",\\n            b\\\"TAU_UPENNBIOMK9_04_19_17\\\",\\n            b\\\"PTAU_UPENNBIOMK9_04_19_17\\\",\\n        ]\\n    ]\\n\\n    # indices = sortedByPvalInd[:300]\\n    # print('pVals lowest', pVals[sortedByPvalInd[:300]])\\n    # print('pVals highest', pVals[sortedByPvalInd[-100:]])\\n    # print('indices', indices)\\n    # print(ads)\\n    ##print('labels', labels[indices])\\n    # print(adsa)\\n    # print(np.nanstd(data,axis=0)[indices])\\n    data = params[\\\"data\\\"][:, indices]\\n    params[\\\"data\\\"] = data\\n    labels = labels[indices]\\n    params[\\\"labels\\\"] = labels\\n    nrBiomk = params[\\\"data\\\"].shape[1]\\n    ##print('data.shape', params['data'].shape)\\n    meanCTL = meanCTL[indices]\\n    stdBiomkRescale = stdBiomkRescale[indices]\\n    ##print(stdBiomkRescale)\\n    ## print('flippedBiomk', labels[stdBiomkRescale < 0])\\n    sortedByPvalInd = np.argsort(np.argsort(sortedByPvalInd[indices]))\\n\\n    # visTadpoleHist(data, diag, ageAtScan, labels, plotTrajParams, sortedByPvalInd)\\n    # print(adsa)\\n\\n    # visTadpoleSpagetti(data, diag, ageAtScan, scanTimepts, partCode, labels, plotTrajParams, sortedByPvalInd)\\n    # print(adsa)\\n\\n    # print('CTL %f +/- %f', np.nanmean(params['data'][params['diag'] == CTL, 1]), np.nanstd(params['data'][params['diag'] == CTL, 1]))\\n    # print('AD %f +/- %f', np.nanmean(params['data'][params['diag'] == AD, 1]), np.nanstd(params['data'][params['diag'] == AD, 1]))\\n    # print(ads)\\n\\n    plotTrajParams[\\\"nearestNeighbours\\\"] = np.array(range(nrBiomk))\\n    params[\\\"adjList\\\"] = np.nan\\n    params[\\\"nearNeighInitClust\\\"] = np.array(range(nrBiomk))\\n    params[\\\"initClustSubsetInd\\\"] = np.array(range(nrBiomk))\\n    params[\\\"meanBiomkRescale\\\"] = meanCTL  # for rescaling back if necessary\\n    params[\\\"stdBiomkRescale\\\"] = stdBiomkRescale\\n    # params['fixSpeed'] = True # if true then don't model progression speed, only time shift\\n    params[\\n        \\\"fixSpeed\\\"\\n    ] = False  # if true then don't model progression speed, only time shift\\n\\n    diagNrs = np.unique(diag)\\n    # print('diagNrs, diag', diagNrs, diag)\\n    # print(asdas)\\n\\n    # print(len(params['acqDate']), data.shape[0])\\n    sys.stdout.flush()\\n    assert (\\n        params[\\\"data\\\"].shape[0]\\n        == params[\\\"diag\\\"].shape[0]\\n        == params[\\\"scanTimepts\\\"].shape[0]\\n        == params[\\\"partCode\\\"].shape[0]\\n        == params[\\\"ageAtScan\\\"].shape[0]\\n    )\\n\\n    # sets an uninformative or informative prior\\n    priorNr = setPrior(\\n        params,\\n        args.get(\\\"informPrior\\\"),\\n        mean_gamma_alpha=1,\\n        std_gamma_alpha=0.1,\\n        mu_beta=0,\\n        std_beta=5,\\n    )\\n\\n    suffix = \\\"\\\"\\n    if args.get(\\\"leaderboard\\\"):\\n        suffix = \\\"Ldb\\\"\\n        # print(ads)\\n\\n    expName = \\\"tadpoleInit%sCl%dPr%dRa%d%s\\\" % (\\n        args.get(\\\"initClustering\\\"),\\n        params[\\\"nrClust\\\"],\\n        priorNr,\\n        args.get(\\\"rangeFactor\\\"),\\n        suffix,\\n    )\\n    plotTrajParams[\\\"sortedByPvalInd\\\"] = sortedByPvalInd\\n    plotTrajParams[\\\"pointIndices\\\"] = pointIndices\\n    plotTrajParams[\\\"expName\\\"] = expName\\n    plotTrajParams[\\\"ageTransform\\\"] = (0, 1)  # no age normalisation was necessary\\n    plotTrajParams[\\\"datasetFull\\\"] = params[\\\"datasetFull\\\"]\\n    plotTrajParams[\\\"labels\\\"] = labels\\n\\n    params[\\\"plotTrajParams\\\"] = plotTrajParams\\n\\n    # R - run that checkpoint, L - load result from checkpoint\\n    # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\\n    params[\\\"runPartStd\\\"] = [\\\"R\\\", \\\"R\\\", \\\"I\\\", \\\"I\\\", \\\"I\\\"]\\n    params[\\\"runPartMain\\\"] = [\\n        \\\"R\\\",\\n        \\\"I\\\",\\n        \\\"I\\\",\\n        \\\"I\\\",\\n    ]  # [mainPart, plot, stage, globalMinStats]\\n    params[\\\"runPartCogCorr\\\"] = [\\\"I\\\"]\\n    params[\\\"runPartCogCorrMain\\\"] = [\\\"L\\\", \\\"L\\\", \\\"I\\\", \\\"I\\\", \\\"L\\\"]\\n    params[\\\"runPartDirDiag\\\"] = [\\\"R\\\", \\\"R\\\", \\\"I\\\"]\\n    params[\\\"runPartStaging\\\"] = [\\\"L\\\", \\\"L\\\", \\\"I\\\"]\\n    params[\\\"runPartDiffDiag\\\"] = [\\\"R\\\", \\\"R\\\", \\\"I\\\"]\\n    params[\\\"runPartConvPred\\\"] = [\\\"I\\\", \\\"I\\\", \\\"I\\\"]\\n    params[\\\"runPartCVNonOverlap\\\"] = [\\\"R\\\"]\\n    params[\\\"runPartCVNonOverlapMain\\\"] = [\\\"L\\\", \\\"L\\\", \\\"I\\\", \\\"I\\\", \\\"L\\\"]\\n    params[\\\"masterProcess\\\"] = runIndex == 0\\n\\n    if params[\\\"masterProcess\\\"]:\\n        # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\\n        params[\\\"runPartStd\\\"] = [\\\"L\\\", \\\"L\\\", \\\"I\\\", \\\"I\\\", \\\"I\\\"]\\n        params[\\\"runPartMain\\\"] = [\\n            \\\"R\\\",\\n            \\\"R\\\",\\n            \\\"R\\\",\\n            \\\"I\\\",\\n        ]  # [mainPart, plot, stage, globalMinStats]\\n        params[\\\"runPartCogCorr\\\"] = [\\\"I\\\"]\\n        params[\\\"runPartCogCorrMain\\\"] = [\\\"L\\\", \\\"L\\\", \\\"I\\\", \\\"I\\\", \\\"I\\\"]\\n        params[\\\"runPartDirDiag\\\"] = [\\\"R\\\", \\\"R\\\", \\\"I\\\"]\\n        params[\\\"runPartStaging\\\"] = [\\\"L\\\", \\\"L\\\", \\\"I\\\"]\\n        params[\\\"runPartDiffDiag\\\"] = [\\\"R\\\", \\\"R\\\", \\\"I\\\"]\\n        params[\\\"runPartConvPred\\\"] = [\\\"I\\\", \\\"I\\\", \\\"I\\\"]\\n        params[\\\"runPartCVNonOverlap\\\"] = [\\\"I\\\"]\\n        params[\\\"runPartCVNonOverlapMain\\\"] = [\\\"R\\\", \\\"R\\\", \\\"I\\\", \\\"R\\\", \\\"R\\\"]\\n\\n    runAllExpFunc = runAllExpTADPOLE\\n    modelNames, res = evaluationFramework.runModels(\\n        params, expName, modelToRun, runAllExpFunc\\n    )\\n\\n    # now generate forecast\\n    # print('Generating forecast ... ')\\n    teamName = \\\"DIVE6\\\"\\n    if args.get(\\\"leaderboard\\\"):\\n        outputFile = \\\"output/TADPOLE_Submission_Leaderboard_%s.csv\\\" % teamName\\n        predStartDate = datetime.date(2010, 5, 1)\\n        nrYearsToPred = 7\\n        nrMonthsToPred = 12 * nrYearsToPred  # 5 years\\n    else:\\n        outputFile = \\\"output/TADPOLE_Submission_%s.csv\\\" % teamName\\n        predStartDate = datetime.date(2018, 1, 1)\\n        nrYearsToPred = 5\\n        nrMonthsToPred = 12 * nrYearsToPred  # 7 years\\n\\n    resCurrModel = res[0][\\\"std\\\"]\\n\\n    predAdasAllSubj, predVentsAllSubj, predDiagAllSubj = makeTadpoleForecast(\\n        predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params\\n    )\\n\\n    # write forecast to file\\n    writeTadpoleSubmission(\\n        predAdasAllSubj,\\n        predVentsAllSubj,\\n        predDiagAllSubj,\\n        outputFile,\\n        nrMonthsToPred,\\n        predStartDate,\\n        params,\\n    )\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def launchTadpole(runIndex, nrProcesses, modelToRun):\n",
    "\n",
    "    genProcessedDataset = 1\n",
    "\n",
    "    if genProcessedDataset:\n",
    "        if args.get(\"leaderboard\") == 0:\n",
    "            inputFileData = \"data/TADPOLE_D1_D2.csv\"\n",
    "            sys.stdout.flush()\n",
    "            outFileCheckpoint2 = \"output/tadpoleDf2.npz\"\n",
    "            # print('loading data file')\n",
    "            df = pd.read_csv(inputFileData, low_memory=False)\n",
    "            df = cleanTadpoleData(df)\n",
    "            data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, examDates, predInd = parseTadpoleData(\n",
    "                df\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            outFileCheckpoint2 = \"output/tadpoleDf2Ldb.npz\"\n",
    "            # print('loading data file')\n",
    "            inputFileDataD1D2 = \"data/TADPOLE_D1_D2.csv\"\n",
    "            df = pd.read_csv(inputFileDataD1D2, low_memory=False)\n",
    "            df = cleanTadpoleData(df)\n",
    "            inputFileDataLB = \"data/TADPOLE_LB1_LB2.csv\"\n",
    "            dfLB = pd.read_csv(inputFileDataLB, low_memory=False)\n",
    "\n",
    "            # this function runs exactly as in the normal submission, no difference here for leaderboard\n",
    "            data, diag, labels, scanTimepts, partCode, ageAtScan, dataDf, monthsSinceRefTime, examDates, _ = parseTadpoleData(\n",
    "                df\n",
    "            )\n",
    "\n",
    "            filterMaskLB12 = np.logical_or(dfLB.LB1 == 1, dfLB.LB2 == 1)\n",
    "            assert data.shape[0] == dfLB.shape[0]\n",
    "\n",
    "            # print(np.sum(filterMaskLB12), filterMaskLB12.shape[0])\n",
    "            # print(dads)\n",
    "\n",
    "            data = data[filterMaskLB12, :]\n",
    "            diag = diag[filterMaskLB12]\n",
    "            scanTimepts = scanTimepts[filterMaskLB12]\n",
    "            partCode = partCode[filterMaskLB12]\n",
    "            ageAtScan = ageAtScan[filterMaskLB12]\n",
    "            dataDf = dataDf[filterMaskLB12]\n",
    "            dataDf.reset_index(drop=True, inplace=True)\n",
    "            dataDf.reindex(index=range(dataDf.shape[0]))\n",
    "            monthsSinceRefTime = monthsSinceRefTime[filterMaskLB12]\n",
    "            examDates = examDates[filterMaskLB12]\n",
    "            predInd = dfLB.RID[dfLB.LB2 == 1].to_numpy()\n",
    "\n",
    "        dataStruct = dict(\n",
    "            data=data,\n",
    "            diag=diag,\n",
    "            labels=labels,\n",
    "            scanTimepts=scanTimepts,\n",
    "            partCode=partCode,\n",
    "            ageAtScan=ageAtScan,\n",
    "            dataDf=dataDf,\n",
    "            monthsSinceRefTime=monthsSinceRefTime,\n",
    "            examDates=examDates,\n",
    "            predInd=predInd,\n",
    "        )\n",
    "        pickle.dump(\n",
    "            dataStruct, open(outFileCheckpoint2, \"wb\"), protocol=pickle.HIGHEST_PROTOCOL\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if args.get(\"leaderboard\") == 0:\n",
    "            outFileCheckpoint2 = \"output/tadpoleDf2.npz\"\n",
    "        else:\n",
    "            outFileCheckpoint2 = \"output/tadpoleDf2Ldb.npz\"\n",
    "\n",
    "    dataStruct = pickle.load(open(outFileCheckpoint2, \"rb\"))\n",
    "    data = dataStruct[\"data\"]\n",
    "    diag = dataStruct[\"diag\"]\n",
    "    labels = dataStruct[\"labels\"]\n",
    "    scanTimepts = dataStruct[\"scanTimepts\"]\n",
    "    partCode = dataStruct[\"partCode\"]\n",
    "    ageAtScan = dataStruct[\"ageAtScan\"]\n",
    "    # dataDf = dataStruct['dataDf']\n",
    "    monthsSinceRefTime = dataStruct[\"monthsSinceRefTime\"]\n",
    "    examDates = dataStruct[\"examDates\"]\n",
    "    predInd = dataStruct[\"predInd\"]\n",
    "\n",
    "    # filter AD subjects\n",
    "    # diagInd = np.array(np.where(matData['diag'] == PCA)[0])\n",
    "    ##print('compiling parameters')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    ##print('diag', np.unique(diag), diag)\n",
    "    # print(adsas)\n",
    "\n",
    "    unqPartCode = np.unique(partCode)\n",
    "    nrUnqPart = len(unqPartCode)\n",
    "\n",
    "    # calculate Z-scores at each point w.r.t controls at baseline\n",
    "    # controlBlInd = np.logical_and(diag == CTL, scanTimepts == 1)\n",
    "    controlInd = diag == CTL\n",
    "    stdBiomk = np.nanstd(data[diag == CTL], 0)\n",
    "    biomkMaskCTL = np.isnan(np.nanstd(data[diag == CTL], 0))\n",
    "    biomkMaskAD = np.isnan(np.nanstd(data[diag == AD], 0))\n",
    "    biomkMaskMCI = np.isnan(np.nanstd(data[diag == MCI], 0))\n",
    "    mask = np.logical_or(np.logical_or(biomkMaskCTL, biomkMaskMCI), biomkMaskAD)\n",
    "    # print(ads)\n",
    "    selectedBiomk = np.logical_not(np.logical_or(mask, stdBiomk == 0))\n",
    "\n",
    "    ##print(data.shape)\n",
    "    data = data[:, selectedBiomk]\n",
    "    labels = labels[selectedBiomk]\n",
    "    pointIndices = np.array(range(data.shape[1]))\n",
    "    stdBiomk = np.nanstd(data[controlInd], 0)\n",
    "    ##print(data.shape)\n",
    "    # print(ads)\n",
    "\n",
    "    meanCTL = np.nanmean(data[controlInd], 0)  # calculate Z-scores\n",
    "    stdCTL = np.nanstd(data[controlInd], 0)\n",
    "    dataZ = (data - meanCTL[None, :]) / stdCTL[None, :]\n",
    "    data = dataZ\n",
    "\n",
    "    outlierRows, outlierCols = np.where(np.abs(dataZ) > 50)\n",
    "    filterMask = np.ones(data.shape[0], bool)\n",
    "    filterMask[outlierRows] = 0\n",
    "    data = data[filterMask]\n",
    "    diag = diag[filterMask]\n",
    "    scanTimepts = scanTimepts[filterMask]\n",
    "    partCode = partCode[filterMask]\n",
    "    ageAtScan = ageAtScan[filterMask]\n",
    "    monthsSinceRefTime = monthsSinceRefTime[filterMask]\n",
    "    examDates = examDates[filterMask]\n",
    "    meanAgeAtScan = np.mean(ageAtScan.astype(float))\n",
    "    ageAtScanCentered = (ageAtScan - meanAgeAtScan).astype(np.float16)\n",
    "\n",
    "    nrSubj, nrBiomk = data.shape\n",
    "    # print('nrBiomk', nrBiomk)\n",
    "    # print(adsa)\n",
    "\n",
    "    dataAD = data[diag == AD, :]\n",
    "\n",
    "    # make all biomarkers decreasing by flipping their signs if necessary\n",
    "    # also perform a t-test to see which ones are most informative, sort them by pvalue (i.e. sortedByPvalInd)\n",
    "    # the new data is re-scaled\n",
    "    data, sortedByPvalInd, biomkScaleExtra, pVals = makeBiomksDecr(data, diag, labels)\n",
    "    # doTtest(data, diag, pointIndices)\n",
    "\n",
    "    # multiply the scaling we did from controls with (-1) if the biomk had the sign flipped\n",
    "    stdBiomkRescale = biomkScaleExtra * stdCTL\n",
    "\n",
    "    assert sortedByPvalInd.shape[0] == data.shape[1]\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    global params\n",
    "\n",
    "    params[\"data\"] = data\n",
    "    params[\"diag\"] = diag\n",
    "    params[\"scanTimepts\"] = scanTimepts\n",
    "    params[\"partCode\"] = partCode\n",
    "    params[\"ageAtScan\"] = ageAtScan\n",
    "    params[\n",
    "        \"initShift\"\n",
    "    ] = ageAtScanCentered  # initialise time shifts (betas) to (age - meanAge)\n",
    "    params[\"biomkDir\"] = DECR\n",
    "    params[\"modelToRun\"] = modelToRun\n",
    "    params[\"datasetFull\"] = \"tadpole\"\n",
    "    params[\"labels\"] = labels\n",
    "    params[\"predInd\"] = predInd\n",
    "    params[\"examDates\"] = examDates\n",
    "\n",
    "    # print('ageAtScanCentered', ageAtScanCentered)\n",
    "    # print('ageAtScan', ageAtScan)\n",
    "    # print('scanTimepts', scanTimepts)\n",
    "    # ada\n",
    "\n",
    "    ## print('outFileCheckpoint2', outFileCheckpoint2)\n",
    "    ## print('d2Ind', np.unique(predInd), np.unique(predInd).shape)\n",
    "    # print(adsa)\n",
    "\n",
    "    # filter down to 100 subjects to make it run faster, just for testing. Also select only some biomarkers\n",
    "    unqPartCode = np.unique(params[\"partCode\"])\n",
    "    nrPartToSample = 30\n",
    "    np.random.seed(3)\n",
    "    selectedPartCode = np.random.choice(unqPartCode, nrPartToSample)\n",
    "    dataIndices = np.in1d(params[\"partCode\"], selectedPartCode)\n",
    "    # params = filterDDSPAIndices(params, dataIndices)\n",
    "\n",
    "    indices = [\n",
    "        i\n",
    "        for i in range(len(labels))\n",
    "        if labels[i]\n",
    "        in [\n",
    "            b\"FDG\",\n",
    "            b\"AV45\",\n",
    "            b\"CDRSB\",\n",
    "            b\"ADAS13\",\n",
    "            b\"Ventricles\",\n",
    "            b\"Hippocampus\",\n",
    "            b\"WholeBrain\",\n",
    "            b\"Entorhinal\",\n",
    "            b\"MidTemp\",\n",
    "            b\"ABETA_UPENNBIOMK9_04_19_17\",\n",
    "            b\"TAU_UPENNBIOMK9_04_19_17\",\n",
    "            b\"PTAU_UPENNBIOMK9_04_19_17\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # indices = sortedByPvalInd[:300]\n",
    "    # print('pVals lowest', pVals[sortedByPvalInd[:300]])\n",
    "    # print('pVals highest', pVals[sortedByPvalInd[-100:]])\n",
    "    # print('indices', indices)\n",
    "    # print(ads)\n",
    "    ##print('labels', labels[indices])\n",
    "    # print(adsa)\n",
    "    # print(np.nanstd(data,axis=0)[indices])\n",
    "    data = params[\"data\"][:, indices]\n",
    "    params[\"data\"] = data\n",
    "    labels = labels[indices]\n",
    "    params[\"labels\"] = labels\n",
    "    nrBiomk = params[\"data\"].shape[1]\n",
    "    ##print('data.shape', params['data'].shape)\n",
    "    meanCTL = meanCTL[indices]\n",
    "    stdBiomkRescale = stdBiomkRescale[indices]\n",
    "    ##print(stdBiomkRescale)\n",
    "    ## print('flippedBiomk', labels[stdBiomkRescale < 0])\n",
    "    sortedByPvalInd = np.argsort(np.argsort(sortedByPvalInd[indices]))\n",
    "\n",
    "    # visTadpoleHist(data, diag, ageAtScan, labels, plotTrajParams, sortedByPvalInd)\n",
    "    # print(adsa)\n",
    "\n",
    "    # visTadpoleSpagetti(data, diag, ageAtScan, scanTimepts, partCode, labels, plotTrajParams, sortedByPvalInd)\n",
    "    # print(adsa)\n",
    "\n",
    "    # print('CTL %f +/- %f', np.nanmean(params['data'][params['diag'] == CTL, 1]), np.nanstd(params['data'][params['diag'] == CTL, 1]))\n",
    "    # print('AD %f +/- %f', np.nanmean(params['data'][params['diag'] == AD, 1]), np.nanstd(params['data'][params['diag'] == AD, 1]))\n",
    "    # print(ads)\n",
    "\n",
    "    plotTrajParams[\"nearestNeighbours\"] = np.array(range(nrBiomk))\n",
    "    params[\"adjList\"] = np.nan\n",
    "    params[\"nearNeighInitClust\"] = np.array(range(nrBiomk))\n",
    "    params[\"initClustSubsetInd\"] = np.array(range(nrBiomk))\n",
    "    params[\"meanBiomkRescale\"] = meanCTL  # for rescaling back if necessary\n",
    "    params[\"stdBiomkRescale\"] = stdBiomkRescale\n",
    "    # params['fixSpeed'] = True # if true then don't model progression speed, only time shift\n",
    "    params[\n",
    "        \"fixSpeed\"\n",
    "    ] = False  # if true then don't model progression speed, only time shift\n",
    "\n",
    "    diagNrs = np.unique(diag)\n",
    "    # print('diagNrs, diag', diagNrs, diag)\n",
    "    # print(asdas)\n",
    "\n",
    "    # print(len(params['acqDate']), data.shape[0])\n",
    "    sys.stdout.flush()\n",
    "    assert (\n",
    "        params[\"data\"].shape[0]\n",
    "        == params[\"diag\"].shape[0]\n",
    "        == params[\"scanTimepts\"].shape[0]\n",
    "        == params[\"partCode\"].shape[0]\n",
    "        == params[\"ageAtScan\"].shape[0]\n",
    "    )\n",
    "\n",
    "    # sets an uninformative or informative prior\n",
    "    priorNr = setPrior(\n",
    "        params,\n",
    "        args.get(\"informPrior\"),\n",
    "        mean_gamma_alpha=1,\n",
    "        std_gamma_alpha=0.1,\n",
    "        mu_beta=0,\n",
    "        std_beta=5,\n",
    "    )\n",
    "\n",
    "    suffix = \"\"\n",
    "    if args.get(\"leaderboard\"):\n",
    "        suffix = \"Ldb\"\n",
    "        # print(ads)\n",
    "\n",
    "    expName = \"tadpoleInit%sCl%dPr%dRa%d%s\" % (\n",
    "        args.get(\"initClustering\"),\n",
    "        params[\"nrClust\"],\n",
    "        priorNr,\n",
    "        args.get(\"rangeFactor\"),\n",
    "        suffix,\n",
    "    )\n",
    "    plotTrajParams[\"sortedByPvalInd\"] = sortedByPvalInd\n",
    "    plotTrajParams[\"pointIndices\"] = pointIndices\n",
    "    plotTrajParams[\"expName\"] = expName\n",
    "    plotTrajParams[\"ageTransform\"] = (0, 1)  # no age normalisation was necessary\n",
    "    plotTrajParams[\"datasetFull\"] = params[\"datasetFull\"]\n",
    "    plotTrajParams[\"labels\"] = labels\n",
    "\n",
    "    params[\"plotTrajParams\"] = plotTrajParams\n",
    "\n",
    "    # R - run that checkpoint, L - load result from checkpoint\n",
    "    # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\n",
    "    params[\"runPartStd\"] = [\"R\", \"R\", \"I\", \"I\", \"I\"]\n",
    "    params[\"runPartMain\"] = [\n",
    "        \"R\",\n",
    "        \"I\",\n",
    "        \"I\",\n",
    "        \"I\",\n",
    "    ]  # [mainPart, plot, stage, globalMinStats]\n",
    "    params[\"runPartCogCorr\"] = [\"I\"]\n",
    "    params[\"runPartCogCorrMain\"] = [\"L\", \"L\", \"I\", \"I\", \"L\"]\n",
    "    params[\"runPartDirDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "    params[\"runPartStaging\"] = [\"L\", \"L\", \"I\"]\n",
    "    params[\"runPartDiffDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "    params[\"runPartConvPred\"] = [\"I\", \"I\", \"I\"]\n",
    "    params[\"runPartCVNonOverlap\"] = [\"R\"]\n",
    "    params[\"runPartCVNonOverlapMain\"] = [\"L\", \"L\", \"I\", \"I\", \"L\"]\n",
    "    params[\"masterProcess\"] = runIndex == 0\n",
    "\n",
    "    if params[\"masterProcess\"]:\n",
    "        # [initClust, modelFit, AIC/BIC, blender, theta_sampling]\n",
    "        params[\"runPartStd\"] = [\"L\", \"L\", \"I\", \"I\", \"I\"]\n",
    "        params[\"runPartMain\"] = [\n",
    "            \"R\",\n",
    "            \"R\",\n",
    "            \"R\",\n",
    "            \"I\",\n",
    "        ]  # [mainPart, plot, stage, globalMinStats]\n",
    "        params[\"runPartCogCorr\"] = [\"I\"]\n",
    "        params[\"runPartCogCorrMain\"] = [\"L\", \"L\", \"I\", \"I\", \"I\"]\n",
    "        params[\"runPartDirDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "        params[\"runPartStaging\"] = [\"L\", \"L\", \"I\"]\n",
    "        params[\"runPartDiffDiag\"] = [\"R\", \"R\", \"I\"]\n",
    "        params[\"runPartConvPred\"] = [\"I\", \"I\", \"I\"]\n",
    "        params[\"runPartCVNonOverlap\"] = [\"I\"]\n",
    "        params[\"runPartCVNonOverlapMain\"] = [\"R\", \"R\", \"I\", \"R\", \"R\"]\n",
    "\n",
    "    runAllExpFunc = runAllExpTADPOLE\n",
    "    modelNames, res = evaluationFramework.runModels(\n",
    "        params, expName, modelToRun, runAllExpFunc\n",
    "    )\n",
    "\n",
    "    # now generate forecast\n",
    "    # print('Generating forecast ... ')\n",
    "    teamName = \"DIVE6\"\n",
    "    if args.get(\"leaderboard\"):\n",
    "        outputFile = \"output/TADPOLE_Submission_Leaderboard_%s.csv\" % teamName\n",
    "        predStartDate = datetime.date(2010, 5, 1)\n",
    "        nrYearsToPred = 7\n",
    "        nrMonthsToPred = 12 * nrYearsToPred  # 5 years\n",
    "    else:\n",
    "        outputFile = \"output/TADPOLE_Submission_%s.csv\" % teamName\n",
    "        predStartDate = datetime.date(2018, 1, 1)\n",
    "        nrYearsToPred = 5\n",
    "        nrMonthsToPred = 12 * nrYearsToPred  # 7 years\n",
    "\n",
    "    resCurrModel = res[0][\"std\"]\n",
    "\n",
    "    predAdasAllSubj, predVentsAllSubj, predDiagAllSubj = makeTadpoleForecast(\n",
    "        predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params\n",
    "    )\n",
    "\n",
    "    # write forecast to file\n",
    "    writeTadpoleSubmission(\n",
    "        predAdasAllSubj,\n",
    "        predVentsAllSubj,\n",
    "        predDiagAllSubj,\n",
    "        outputFile,\n",
    "        nrMonthsToPred,\n",
    "        predStartDate,\n",
    "        params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 13;\n",
       "            var nbb_formatted_code = \"def makeTadpoleForecast(\\n    predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params\\n):\\n\\n    yearsFromPredStartToEachPredDate = np.linspace(\\n        0, nrYearsToPred, num=nrMonthsToPred, endpoint=False\\n    )\\n\\n    nrClust = params[\\\"nrClust\\\"]\\n    assert abs(yearsFromPredStartToEachPredDate[1] - (1.0 / 12)) < 0.00001\\n    # make predictions\\n    startMonth = dateDiffToMonths(refDate - predStartDate)\\n\\n    trajFunc = sigmoidFunc\\n\\n    unqPartCodeFromRes = resCurrModel[\\\"uniquePartCode\\\"]\\n    predInd = params[\\\"predInd\\\"]\\n    predSetRidUnq = np.unique(predInd)\\n\\n    nrSubjPredSet = predSetRidUnq.shape[0]\\n    # for each patient\\n    clustProbBC = resCurrModel[\\\"clustProb\\\"]\\n    thetas = resCurrModel[\\\"thetas\\\"]\\n    variances = resCurrModel[\\\"variances\\\"]\\n\\n    labels = params[\\\"labels\\\"]\\n    indexAdas = np.where(labels == b\\\"ADAS13\\\")[0][0]\\n    indexVents = np.where(labels == b\\\"Ventricles\\\")[0][0]\\n\\n    predDiagAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\\n    predAdasAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\\n    predVentsAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\\n\\n    dpsCross = resCurrModel[\\\"dpsCross\\\"]\\n    crossDiag = resCurrModel[\\\"crossDiag\\\"]\\n\\n    dpsCTL = dpsCross[crossDiag == CTL]\\n    dpsMCI = dpsCross[crossDiag == MCI]\\n    dpsAD = dpsCross[crossDiag == AD]\\n\\n    partCode = params[\\\"partCode\\\"]\\n    partCodeCurr = resCurrModel[\\\"crossPartCode\\\"]\\n    # ageAtScan = resCurrModel['ageAtScan']\\n\\n    data = params[\\\"data\\\"]\\n\\n    assert partCodeCurr.shape[0] == partCode.shape[0]\\n\\n    kernelWidth = np.std(dpsCross) / 6  # need to test this parameter by visualisation\\n\\n    from sklearn.neighbors.kde import KernelDensity\\n\\n    kdeCTL = KernelDensity(kernel=\\\"gaussian\\\", bandwidth=kernelWidth).fit(\\n        dpsCTL.reshape(-1, 1)\\n    )\\n    kdeMCI = KernelDensity(kernel=\\\"gaussian\\\", bandwidth=kernelWidth).fit(\\n        dpsMCI.reshape(-1, 1)\\n    )\\n    kdeAD = KernelDensity(kernel=\\\"gaussian\\\", bandwidth=kernelWidth).fit(\\n        dpsAD.reshape(-1, 1)\\n    )\\n\\n    kdeXs = np.linspace(np.min(dpsCross), np.max(dpsCross), num=100).reshape(-1, 1)\\n\\n    fig = pl.figure(3)\\n    pl.clf()\\n    # print('kdeCTL.score_samples(kdeXs)', np.exp(kdeCTL.score_samples(kdeXs)))\\n    pl.plot(\\n        kdeXs,\\n        np.exp(kdeCTL.score_samples(kdeXs)),\\n        label=\\\"CTL\\\",\\n        c=plotTrajParams[\\\"diagColors\\\"][CTL],\\n    )\\n    pl.plot(\\n        kdeXs,\\n        np.exp(kdeMCI.score_samples(kdeXs)),\\n        label=\\\"MCI\\\",\\n        c=plotTrajParams[\\\"diagColors\\\"][MCI],\\n    )\\n    pl.plot(\\n        kdeXs,\\n        np.exp(kdeAD.score_samples(kdeXs)),\\n        label=\\\"AD\\\",\\n        c=plotTrajParams[\\\"diagColors\\\"][AD],\\n    )\\n    pl.legend()\\n    fig.show()\\n    fig.savefig(\\\"%s/diagHist.png\\\" % (resCurrModel[\\\"outFolder\\\"]), dpi=100)\\n\\n    ageAtScan = params[\\\"ageAtScan\\\"]\\n    examDates = params[\\\"examDates\\\"]\\n\\n    runPred = \\\"R\\\"\\n    doPlot = 0\\n    predFile = \\\"output/tadpolePredD2.npz\\\"\\n\\n    meanBiomkRescale = params[\\\"meanBiomkRescale\\\"]\\n    stdBiomkRescale = params[\\\"stdBiomkRescale\\\"]\\n\\n    if runPred == \\\"R\\\":\\n        for s in range(nrSubjPredSet):\\n\\n            ######### find dps at forecasted months ##########\\n\\n            # find age at forecasted months\\n            subjRowsCurr = partCode == predSetRidUnq[s]\\n\\n            # import pdb\\n            # pdb.set_trace()\\n\\n            # for one timepoint, find the age and the examDate\\n            # print('part : ', predSetRidUnq[s], np.sum(subjRowsCurr))\\n            # print('part ageAtScan: ', predSetRidUnq[s], ageAtScan[subjRowsCurr][0])\\n\\n            # compute age of subject at every prediction date\\n            ageOneTimept = ageAtScan[subjRowsCurr][0]\\n            examDateOneTimept = datetime.datetime.strptime(\\n                examDates[subjRowsCurr][0], \\\"%Y-%m-%d\\\"\\n            ).date()\\n            yearsToPredStartDate = (predStartDate - examDateOneTimept).days / 365\\n            ageAtPredDates = (\\n                ageOneTimept + yearsToPredStartDate + yearsFromPredStartToEachPredDate\\n            )\\n\\n            # compute dps\\n            subShiftsCurr = resCurrModel[\\\"subShifts\\\"][\\n                unqPartCodeFromRes == predSetRidUnq[s]\\n            ]\\n            dpsAtFutForecastDatesCurr = calcDpsGivenAges(ageAtPredDates, subShiftsCurr)\\n\\n            ######## find model predictions for those DPSs ##############3\\n\\n            futureForecastsAdas, futureForecastsVents = calcModelPredAdasVents(\\n                dpsAtFutForecastDatesCurr,\\n                thetas,\\n                variances,\\n                clustProbBC[indexAdas, :].T,\\n                clustProbBC[indexVents, :].T,\\n                trajFunc,\\n            )\\n\\n            # add subject-specific intercept to the predictions, is subject has data\\n            # warning: can contain NaNs and even be NaN in all entries.\\n            adasDataCurrSubj = data[subjRowsCurr, indexAdas]\\n            ventsDataCurrSubj = data[subjRowsCurr, indexVents]\\n\\n            ageCurrVisits = ageAtScan[subjRowsCurr]\\n            dpsSubjCurrVisits = calcDpsGivenAges(ageCurrVisits, subShiftsCurr)\\n            currVisitsPredAdas, currVisitsPredVents = calcModelPredAdasVents(\\n                dpsSubjCurrVisits,\\n                thetas,\\n                variances,\\n                clustProbBC[indexAdas, :].T,\\n                clustProbBC[indexVents, :].T,\\n                trajFunc,\\n            )\\n\\n            futureForecastsAdas = addSubjIntercept(\\n                dpsAtFutForecastDatesCurr,\\n                futureForecastsAdas,\\n                adasDataCurrSubj,\\n                currVisitsPredAdas,\\n            )\\n            futureForecastsVents = addSubjIntercept(\\n                dpsAtFutForecastDatesCurr,\\n                futureForecastsVents,\\n                ventsDataCurrSubj,\\n                currVisitsPredVents,\\n            )\\n\\n            # convert predictions back to un-normalised values\\n\\n            predAdasNotNorm = (\\n                futureForecastsAdas * stdBiomkRescale[indexAdas]\\n                + meanBiomkRescale[indexAdas]\\n            )\\n            predVentsNotNorm = (\\n                futureForecastsVents * stdBiomkRescale[indexVents]\\n                + meanBiomkRescale[indexVents]\\n            )\\n\\n            predAdasAllSubj[s, :, :] = predAdasNotNorm\\n            predAdasAllSubj[s, :, 1] = predAdasNotNorm[\\n                :, 2\\n            ]  # need invert lower& upper bounds due to sign change\\n            predAdasAllSubj[s, :, 2] = predAdasNotNorm[:, 1]\\n\\n            predVentsAllSubj[s, :, :] = predVentsNotNorm\\n            predVentsAllSubj[s, :, 1] = predVentsNotNorm[:, 2]\\n            predVentsAllSubj[s, :, 2] = predVentsNotNorm[:, 1]\\n\\n            # print('predAdasNotNorm', predAdasNotNorm[0,:])\\n            # print(adsa)\\n\\n            adasDataCurrSubjUnnorm = (\\n                adasDataCurrSubj * stdBiomkRescale[indexAdas]\\n                + meanBiomkRescale[indexAdas]\\n            )\\n            ventsDataCurrSubjUnnorm = (\\n                ventsDataCurrSubj * stdBiomkRescale[indexVents]\\n                + meanBiomkRescale[indexVents]\\n            )\\n\\n            ctlLik = np.exp(\\n                kdeCTL.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\\n            )\\n            mciLik = np.exp(\\n                kdeMCI.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\\n            )\\n            adLik = np.exp(\\n                kdeAD.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\\n            )\\n\\n            sumLik = ctlLik + mciLik + adLik\\n\\n            predDiagAllSubj[s, :, 0] = ctlLik / sumLik\\n            predDiagAllSubj[s, :, 1] = mciLik / sumLik\\n            predDiagAllSubj[s, :, 2] = adLik / sumLik\\n\\n            if doPlot:\\n                if args.get(\\\"leaderboard\\\"):\\n                    lb4Data = pd.read_csv(\\\"data/TADPOLE_LB4.csv\\\")\\n                    lb4Data[\\\"CognitiveAssessmentDate\\\"] = [\\n                        datetime.datetime.strptime(x, \\\"%Y-%m-%d\\\")\\n                        for x in lb4Data[\\\"CognitiveAssessmentDate\\\"]\\n                    ]\\n                    lb4Data[\\\"ScanDate\\\"] = [\\n                        datetime.datetime.strptime(x, \\\"%Y-%m-%d\\\").date()\\n                        for x in lb4Data[\\\"ScanDate\\\"]\\n                    ]\\n                    mapping = {\\\"CN\\\": 0, \\\"MCI\\\": 1, \\\"AD\\\": 2}\\n                    lb4Data.replace({\\\"Diagnosis\\\": mapping}, inplace=True)\\n\\n                    currSubjMaskLB4 = lb4Data.RID == predSetRidUnq[s]\\n                    adasLB4CurrSubj = lb4Data.ADAS13[currSubjMaskLB4]\\n                    ventsLB4CurrSubj = lb4Data.Ventricles[currSubjMaskLB4]\\n                    diagLB4CurrSubj = lb4Data.Diagnosis[currSubjMaskLB4]\\n\\n                    datesLB4CurrSubj = lb4Data[\\\"CognitiveAssessmentDate\\\"][\\n                        currSubjMaskLB4\\n                    ]\\n\\n                    yearsFromRefDateToLB4Dates = np.array(\\n                        [\\n                            (d.date() - examDateOneTimept).days / 365\\n                            for d in datesLB4CurrSubj\\n                        ]\\n                    )\\n                    ageAtLB4datesCurrSubj = ageOneTimept + yearsFromRefDateToLB4Dates\\n\\n                    lb4Params = dict(\\n                        adasLB4CurrSubj=adasLB4CurrSubj,\\n                        ventsLB4CurrSubj=ventsLB4CurrSubj,\\n                        diagLB4CurrSubj=diagLB4CurrSubj,\\n                        ageAtLB4datesCurrSubj=ageAtLB4datesCurrSubj,\\n                    )\\n\\n                else:\\n                    lb4Params = None\\n\\n                plotSubjForecasts(\\n                    predAdasAllSubj[s, :, :],\\n                    predVentsAllSubj[s, :, :],\\n                    predDiagAllSubj[s, :, :],\\n                    ageAtPredDates,\\n                    adasDataCurrSubjUnnorm,\\n                    ventsDataCurrSubjUnnorm,\\n                    ageCurrVisits,\\n                    lb4Params,\\n                    rid=predSetRidUnq[s],\\n                )\\n\\n        ds = dict(\\n            predAdasAllSubj=predAdasAllSubj,\\n            predVentsAllSubj=predVentsAllSubj,\\n            predDiagAllSubj=predDiagAllSubj,\\n        )\\n        pickle.dump(ds, open(predFile, \\\"wb\\\"), protocol=pickle.HIGHEST_PROTOCOL)\\n\\n    else:\\n        ds = pickle.load(open(predFile, \\\"rb\\\"))\\n        predAdasAllSubj = ds[\\\"predAdasAllSubj\\\"]\\n        predVentsAllSubj = ds[\\\"predVentsAllSubj\\\"]\\n        predDiagAllSubj = ds[\\\"predDiagAllSubj\\\"]\\n\\n    return predAdasAllSubj, predVentsAllSubj, predDiagAllSubj\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def makeTadpoleForecast(\n",
    "    predStartDate, nrYearsToPred, nrMonthsToPred, resCurrModel, params\n",
    "):\n",
    "\n",
    "    yearsFromPredStartToEachPredDate = np.linspace(\n",
    "        0, nrYearsToPred, num=nrMonthsToPred, endpoint=False\n",
    "    )\n",
    "\n",
    "    nrClust = params[\"nrClust\"]\n",
    "    assert abs(yearsFromPredStartToEachPredDate[1] - (1.0 / 12)) < 0.00001\n",
    "    # make predictions\n",
    "    startMonth = dateDiffToMonths(refDate - predStartDate)\n",
    "\n",
    "    trajFunc = sigmoidFunc\n",
    "\n",
    "    unqPartCodeFromRes = resCurrModel[\"uniquePartCode\"]\n",
    "    predInd = params[\"predInd\"]\n",
    "    predSetRidUnq = np.unique(predInd)\n",
    "\n",
    "    nrSubjPredSet = predSetRidUnq.shape[0]\n",
    "    # for each patient\n",
    "    clustProbBC = resCurrModel[\"clustProb\"]\n",
    "    thetas = resCurrModel[\"thetas\"]\n",
    "    variances = resCurrModel[\"variances\"]\n",
    "\n",
    "    labels = params[\"labels\"]\n",
    "    indexAdas = np.where(labels == b\"ADAS13\")[0][0]\n",
    "    indexVents = np.where(labels == b\"Ventricles\")[0][0]\n",
    "\n",
    "    predDiagAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "    predAdasAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "    predVentsAllSubj = np.zeros((nrSubjPredSet, nrMonthsToPred, 3), np.float)\n",
    "\n",
    "    dpsCross = resCurrModel[\"dpsCross\"]\n",
    "    crossDiag = resCurrModel[\"crossDiag\"]\n",
    "\n",
    "    dpsCTL = dpsCross[crossDiag == CTL]\n",
    "    dpsMCI = dpsCross[crossDiag == MCI]\n",
    "    dpsAD = dpsCross[crossDiag == AD]\n",
    "\n",
    "    partCode = params[\"partCode\"]\n",
    "    partCodeCurr = resCurrModel[\"crossPartCode\"]\n",
    "    # ageAtScan = resCurrModel['ageAtScan']\n",
    "\n",
    "    data = params[\"data\"]\n",
    "\n",
    "    assert partCodeCurr.shape[0] == partCode.shape[0]\n",
    "\n",
    "    kernelWidth = np.std(dpsCross) / 6  # need to test this parameter by visualisation\n",
    "\n",
    "    from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "    kdeCTL = KernelDensity(kernel=\"gaussian\", bandwidth=kernelWidth).fit(\n",
    "        dpsCTL.reshape(-1, 1)\n",
    "    )\n",
    "    kdeMCI = KernelDensity(kernel=\"gaussian\", bandwidth=kernelWidth).fit(\n",
    "        dpsMCI.reshape(-1, 1)\n",
    "    )\n",
    "    kdeAD = KernelDensity(kernel=\"gaussian\", bandwidth=kernelWidth).fit(\n",
    "        dpsAD.reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    kdeXs = np.linspace(np.min(dpsCross), np.max(dpsCross), num=100).reshape(-1, 1)\n",
    "\n",
    "    fig = pl.figure(3)\n",
    "    pl.clf()\n",
    "    # print('kdeCTL.score_samples(kdeXs)', np.exp(kdeCTL.score_samples(kdeXs)))\n",
    "    pl.plot(\n",
    "        kdeXs,\n",
    "        np.exp(kdeCTL.score_samples(kdeXs)),\n",
    "        label=\"CTL\",\n",
    "        c=plotTrajParams[\"diagColors\"][CTL],\n",
    "    )\n",
    "    pl.plot(\n",
    "        kdeXs,\n",
    "        np.exp(kdeMCI.score_samples(kdeXs)),\n",
    "        label=\"MCI\",\n",
    "        c=plotTrajParams[\"diagColors\"][MCI],\n",
    "    )\n",
    "    pl.plot(\n",
    "        kdeXs,\n",
    "        np.exp(kdeAD.score_samples(kdeXs)),\n",
    "        label=\"AD\",\n",
    "        c=plotTrajParams[\"diagColors\"][AD],\n",
    "    )\n",
    "    pl.legend()\n",
    "    fig.show()\n",
    "    fig.savefig(\"%s/diagHist.png\" % (resCurrModel[\"outFolder\"]), dpi=100)\n",
    "\n",
    "    ageAtScan = params[\"ageAtScan\"]\n",
    "    examDates = params[\"examDates\"]\n",
    "\n",
    "    runPred = \"R\"\n",
    "    doPlot = 0\n",
    "    predFile = \"output/tadpolePredD2.npz\"\n",
    "\n",
    "    meanBiomkRescale = params[\"meanBiomkRescale\"]\n",
    "    stdBiomkRescale = params[\"stdBiomkRescale\"]\n",
    "\n",
    "    if runPred == \"R\":\n",
    "        for s in range(nrSubjPredSet):\n",
    "\n",
    "            ######### find dps at forecasted months ##########\n",
    "\n",
    "            # find age at forecasted months\n",
    "            subjRowsCurr = partCode == predSetRidUnq[s]\n",
    "\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "\n",
    "            # for one timepoint, find the age and the examDate\n",
    "            # print('part : ', predSetRidUnq[s], np.sum(subjRowsCurr))\n",
    "            # print('part ageAtScan: ', predSetRidUnq[s], ageAtScan[subjRowsCurr][0])\n",
    "\n",
    "            # compute age of subject at every prediction date\n",
    "            ageOneTimept = ageAtScan[subjRowsCurr][0]\n",
    "            examDateOneTimept = datetime.datetime.strptime(\n",
    "                examDates[subjRowsCurr][0], \"%Y-%m-%d\"\n",
    "            ).date()\n",
    "            yearsToPredStartDate = (predStartDate - examDateOneTimept).days / 365\n",
    "            ageAtPredDates = (\n",
    "                ageOneTimept + yearsToPredStartDate + yearsFromPredStartToEachPredDate\n",
    "            )\n",
    "\n",
    "            # compute dps\n",
    "            subShiftsCurr = resCurrModel[\"subShifts\"][\n",
    "                unqPartCodeFromRes == predSetRidUnq[s]\n",
    "            ]\n",
    "            dpsAtFutForecastDatesCurr = calcDpsGivenAges(ageAtPredDates, subShiftsCurr)\n",
    "\n",
    "            ######## find model predictions for those DPSs ##############3\n",
    "\n",
    "            futureForecastsAdas, futureForecastsVents = calcModelPredAdasVents(\n",
    "                dpsAtFutForecastDatesCurr,\n",
    "                thetas,\n",
    "                variances,\n",
    "                clustProbBC[indexAdas, :].T,\n",
    "                clustProbBC[indexVents, :].T,\n",
    "                trajFunc,\n",
    "            )\n",
    "\n",
    "            # add subject-specific intercept to the predictions, is subject has data\n",
    "            # warning: can contain NaNs and even be NaN in all entries.\n",
    "            adasDataCurrSubj = data[subjRowsCurr, indexAdas]\n",
    "            ventsDataCurrSubj = data[subjRowsCurr, indexVents]\n",
    "\n",
    "            ageCurrVisits = ageAtScan[subjRowsCurr]\n",
    "            dpsSubjCurrVisits = calcDpsGivenAges(ageCurrVisits, subShiftsCurr)\n",
    "            currVisitsPredAdas, currVisitsPredVents = calcModelPredAdasVents(\n",
    "                dpsSubjCurrVisits,\n",
    "                thetas,\n",
    "                variances,\n",
    "                clustProbBC[indexAdas, :].T,\n",
    "                clustProbBC[indexVents, :].T,\n",
    "                trajFunc,\n",
    "            )\n",
    "\n",
    "            futureForecastsAdas = addSubjIntercept(\n",
    "                dpsAtFutForecastDatesCurr,\n",
    "                futureForecastsAdas,\n",
    "                adasDataCurrSubj,\n",
    "                currVisitsPredAdas,\n",
    "            )\n",
    "            futureForecastsVents = addSubjIntercept(\n",
    "                dpsAtFutForecastDatesCurr,\n",
    "                futureForecastsVents,\n",
    "                ventsDataCurrSubj,\n",
    "                currVisitsPredVents,\n",
    "            )\n",
    "\n",
    "            # convert predictions back to un-normalised values\n",
    "\n",
    "            predAdasNotNorm = (\n",
    "                futureForecastsAdas * stdBiomkRescale[indexAdas]\n",
    "                + meanBiomkRescale[indexAdas]\n",
    "            )\n",
    "            predVentsNotNorm = (\n",
    "                futureForecastsVents * stdBiomkRescale[indexVents]\n",
    "                + meanBiomkRescale[indexVents]\n",
    "            )\n",
    "\n",
    "            predAdasAllSubj[s, :, :] = predAdasNotNorm\n",
    "            predAdasAllSubj[s, :, 1] = predAdasNotNorm[\n",
    "                :, 2\n",
    "            ]  # need invert lower& upper bounds due to sign change\n",
    "            predAdasAllSubj[s, :, 2] = predAdasNotNorm[:, 1]\n",
    "\n",
    "            predVentsAllSubj[s, :, :] = predVentsNotNorm\n",
    "            predVentsAllSubj[s, :, 1] = predVentsNotNorm[:, 2]\n",
    "            predVentsAllSubj[s, :, 2] = predVentsNotNorm[:, 1]\n",
    "\n",
    "            # print('predAdasNotNorm', predAdasNotNorm[0,:])\n",
    "            # print(adsa)\n",
    "\n",
    "            adasDataCurrSubjUnnorm = (\n",
    "                adasDataCurrSubj * stdBiomkRescale[indexAdas]\n",
    "                + meanBiomkRescale[indexAdas]\n",
    "            )\n",
    "            ventsDataCurrSubjUnnorm = (\n",
    "                ventsDataCurrSubj * stdBiomkRescale[indexVents]\n",
    "                + meanBiomkRescale[indexVents]\n",
    "            )\n",
    "\n",
    "            ctlLik = np.exp(\n",
    "                kdeCTL.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\n",
    "            )\n",
    "            mciLik = np.exp(\n",
    "                kdeMCI.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\n",
    "            )\n",
    "            adLik = np.exp(\n",
    "                kdeAD.score_samples(dpsAtFutForecastDatesCurr.reshape(-1, 1))\n",
    "            )\n",
    "\n",
    "            sumLik = ctlLik + mciLik + adLik\n",
    "\n",
    "            predDiagAllSubj[s, :, 0] = ctlLik / sumLik\n",
    "            predDiagAllSubj[s, :, 1] = mciLik / sumLik\n",
    "            predDiagAllSubj[s, :, 2] = adLik / sumLik\n",
    "\n",
    "            if doPlot:\n",
    "                if args.get(\"leaderboard\"):\n",
    "                    lb4Data = pd.read_csv(\"data/TADPOLE_LB4.csv\")\n",
    "                    lb4Data[\"CognitiveAssessmentDate\"] = [\n",
    "                        datetime.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "                        for x in lb4Data[\"CognitiveAssessmentDate\"]\n",
    "                    ]\n",
    "                    lb4Data[\"ScanDate\"] = [\n",
    "                        datetime.datetime.strptime(x, \"%Y-%m-%d\").date()\n",
    "                        for x in lb4Data[\"ScanDate\"]\n",
    "                    ]\n",
    "                    mapping = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "                    lb4Data.replace({\"Diagnosis\": mapping}, inplace=True)\n",
    "\n",
    "                    currSubjMaskLB4 = lb4Data.RID == predSetRidUnq[s]\n",
    "                    adasLB4CurrSubj = lb4Data.ADAS13[currSubjMaskLB4]\n",
    "                    ventsLB4CurrSubj = lb4Data.Ventricles[currSubjMaskLB4]\n",
    "                    diagLB4CurrSubj = lb4Data.Diagnosis[currSubjMaskLB4]\n",
    "\n",
    "                    datesLB4CurrSubj = lb4Data[\"CognitiveAssessmentDate\"][\n",
    "                        currSubjMaskLB4\n",
    "                    ]\n",
    "\n",
    "                    yearsFromRefDateToLB4Dates = np.array(\n",
    "                        [\n",
    "                            (d.date() - examDateOneTimept).days / 365\n",
    "                            for d in datesLB4CurrSubj\n",
    "                        ]\n",
    "                    )\n",
    "                    ageAtLB4datesCurrSubj = ageOneTimept + yearsFromRefDateToLB4Dates\n",
    "\n",
    "                    lb4Params = dict(\n",
    "                        adasLB4CurrSubj=adasLB4CurrSubj,\n",
    "                        ventsLB4CurrSubj=ventsLB4CurrSubj,\n",
    "                        diagLB4CurrSubj=diagLB4CurrSubj,\n",
    "                        ageAtLB4datesCurrSubj=ageAtLB4datesCurrSubj,\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    lb4Params = None\n",
    "\n",
    "                plotSubjForecasts(\n",
    "                    predAdasAllSubj[s, :, :],\n",
    "                    predVentsAllSubj[s, :, :],\n",
    "                    predDiagAllSubj[s, :, :],\n",
    "                    ageAtPredDates,\n",
    "                    adasDataCurrSubjUnnorm,\n",
    "                    ventsDataCurrSubjUnnorm,\n",
    "                    ageCurrVisits,\n",
    "                    lb4Params,\n",
    "                    rid=predSetRidUnq[s],\n",
    "                )\n",
    "\n",
    "        ds = dict(\n",
    "            predAdasAllSubj=predAdasAllSubj,\n",
    "            predVentsAllSubj=predVentsAllSubj,\n",
    "            predDiagAllSubj=predDiagAllSubj,\n",
    "        )\n",
    "        pickle.dump(ds, open(predFile, \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    else:\n",
    "        ds = pickle.load(open(predFile, \"rb\"))\n",
    "        predAdasAllSubj = ds[\"predAdasAllSubj\"]\n",
    "        predVentsAllSubj = ds[\"predVentsAllSubj\"]\n",
    "        predDiagAllSubj = ds[\"predDiagAllSubj\"]\n",
    "\n",
    "    return predAdasAllSubj, predVentsAllSubj, predDiagAllSubj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 14;\n",
       "            var nbb_formatted_code = \"def plotSubjForecasts(\\n    predAdasCurrSubj,\\n    predVentsCurrSubj,\\n    predDiagCurrSubj,\\n    ageAtPredDates,\\n    adasDataCurrSubjUnnorm,\\n    ventsDataCurrSubjUnnorm,\\n    ageCurrVisits,\\n    lb4Params,\\n    rid,\\n):\\n\\n    if lb4Params is not None:\\n        adasLB4CurrSubj = lb4Params[\\\"adasLB4CurrSubj\\\"]\\n        ventsLB4CurrSubj = lb4Params[\\\"ventsLB4CurrSubj\\\"]\\n        diagLB4CurrSubj = lb4Params[\\\"diagLB4CurrSubj\\\"]\\n        ageAtLB4datesCurrSubj = lb4Params[\\\"ageAtLB4datesCurrSubj\\\"]\\n\\n    pl.figure(3)\\n    ax = pl.subplot(1, 2, 1)\\n    ax.set_title(\\\"ADAS RID:%d\\\" % rid)\\n    pl.plot(ageAtPredDates, predAdasCurrSubj)\\n    pl.scatter(ageCurrVisits, adasDataCurrSubjUnnorm, c=\\\"b\\\", s=10)\\n    if lb4Params is not None:\\n        pl.scatter(ageAtLB4datesCurrSubj, adasLB4CurrSubj, c=\\\"r\\\", s=10)\\n\\n    ax = pl.subplot(1, 2, 2)\\n    ax.set_title(\\\"Vents RID:%d\\\" % rid)\\n    pl.plot(ageAtPredDates, predVentsCurrSubj)\\n    pl.scatter(ageCurrVisits, ventsDataCurrSubjUnnorm, c=\\\"b\\\", s=10)\\n    if lb4Params is not None:\\n        pl.scatter(ageAtLB4datesCurrSubj, ventsLB4CurrSubj, c=\\\"r\\\", s=10)\\n\\n    pl.show()\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotSubjForecasts(\n",
    "    predAdasCurrSubj,\n",
    "    predVentsCurrSubj,\n",
    "    predDiagCurrSubj,\n",
    "    ageAtPredDates,\n",
    "    adasDataCurrSubjUnnorm,\n",
    "    ventsDataCurrSubjUnnorm,\n",
    "    ageCurrVisits,\n",
    "    lb4Params,\n",
    "    rid,\n",
    "):\n",
    "\n",
    "    if lb4Params is not None:\n",
    "        adasLB4CurrSubj = lb4Params[\"adasLB4CurrSubj\"]\n",
    "        ventsLB4CurrSubj = lb4Params[\"ventsLB4CurrSubj\"]\n",
    "        diagLB4CurrSubj = lb4Params[\"diagLB4CurrSubj\"]\n",
    "        ageAtLB4datesCurrSubj = lb4Params[\"ageAtLB4datesCurrSubj\"]\n",
    "\n",
    "    pl.figure(3)\n",
    "    ax = pl.subplot(1, 2, 1)\n",
    "    ax.set_title(\"ADAS RID:%d\" % rid)\n",
    "    pl.plot(ageAtPredDates, predAdasCurrSubj)\n",
    "    pl.scatter(ageCurrVisits, adasDataCurrSubjUnnorm, c=\"b\", s=10)\n",
    "    if lb4Params is not None:\n",
    "        pl.scatter(ageAtLB4datesCurrSubj, adasLB4CurrSubj, c=\"r\", s=10)\n",
    "\n",
    "    ax = pl.subplot(1, 2, 2)\n",
    "    ax.set_title(\"Vents RID:%d\" % rid)\n",
    "    pl.plot(ageAtPredDates, predVentsCurrSubj)\n",
    "    pl.scatter(ageCurrVisits, ventsDataCurrSubjUnnorm, c=\"b\", s=10)\n",
    "    if lb4Params is not None:\n",
    "        pl.scatter(ageAtLB4datesCurrSubj, ventsLB4CurrSubj, c=\"r\", s=10)\n",
    "\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 15;\n",
       "            var nbb_formatted_code = \"def calcModelPredAdasVents(\\n    dpsPredCurr, thetas, variances, clustProbAdas, clustProbVents, trajFunc\\n):\\n\\n    nrClust = thetas.shape[0]\\n    predCurrSubClustSC = np.zeros((dpsPredCurr.shape[0], nrClust), float)\\n    predCurrSubClustSClower = np.zeros((dpsPredCurr.shape[0], nrClust), float)\\n    predCurrSubClustSCupper = np.zeros((dpsPredCurr.shape[0], nrClust), float)\\n\\n    for c in range(nrClust):\\n        predCurrSubClustSC[:, c] = trajFunc(dpsPredCurr, thetas[c, :])\\n        predCurrSubClustSClower[:, c] = predCurrSubClustSC[:, c] - 0.33 * np.sqrt(\\n            variances[c]\\n        )\\n        predCurrSubClustSCupper[:, c] = predCurrSubClustSC[:, c] + 0.33 * np.sqrt(\\n            variances[c]\\n        )\\n\\n    # from the predictions of each cluster trajectories, predict traj of ADAS and Vents\\n    # using the probabilities of ADAS/Vents of being assigned to each cluster\\n    futureForecastsAdas = np.zeros((predCurrSubClustSC.shape[0], 3))\\n    futureForecastsVents = np.zeros((predCurrSubClustSC.shape[0], 3))\\n\\n    futureForecastsAdas[:, 0] = np.dot(predCurrSubClustSC, clustProbAdas)\\n    futureForecastsVents[:, 0] = np.dot(predCurrSubClustSC, clustProbVents)\\n\\n    futureForecastsAdas[:, 1] = np.dot(predCurrSubClustSClower, clustProbAdas)\\n    futureForecastsVents[:, 1] = np.dot(predCurrSubClustSClower, clustProbVents)\\n\\n    futureForecastsAdas[:, 2] = np.dot(predCurrSubClustSCupper, clustProbAdas)\\n    futureForecastsVents[:, 2] = np.dot(predCurrSubClustSCupper, clustProbVents)\\n\\n    return futureForecastsAdas, futureForecastsVents\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calcModelPredAdasVents(\n",
    "    dpsPredCurr, thetas, variances, clustProbAdas, clustProbVents, trajFunc\n",
    "):\n",
    "\n",
    "    nrClust = thetas.shape[0]\n",
    "    predCurrSubClustSC = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "    predCurrSubClustSClower = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "    predCurrSubClustSCupper = np.zeros((dpsPredCurr.shape[0], nrClust), float)\n",
    "\n",
    "    for c in range(nrClust):\n",
    "        predCurrSubClustSC[:, c] = trajFunc(dpsPredCurr, thetas[c, :])\n",
    "        predCurrSubClustSClower[:, c] = predCurrSubClustSC[:, c] - 0.33 * np.sqrt(\n",
    "            variances[c]\n",
    "        )\n",
    "        predCurrSubClustSCupper[:, c] = predCurrSubClustSC[:, c] + 0.33 * np.sqrt(\n",
    "            variances[c]\n",
    "        )\n",
    "\n",
    "    # from the predictions of each cluster trajectories, predict traj of ADAS and Vents\n",
    "    # using the probabilities of ADAS/Vents of being assigned to each cluster\n",
    "    futureForecastsAdas = np.zeros((predCurrSubClustSC.shape[0], 3))\n",
    "    futureForecastsVents = np.zeros((predCurrSubClustSC.shape[0], 3))\n",
    "\n",
    "    futureForecastsAdas[:, 0] = np.dot(predCurrSubClustSC, clustProbAdas)\n",
    "    futureForecastsVents[:, 0] = np.dot(predCurrSubClustSC, clustProbVents)\n",
    "\n",
    "    futureForecastsAdas[:, 1] = np.dot(predCurrSubClustSClower, clustProbAdas)\n",
    "    futureForecastsVents[:, 1] = np.dot(predCurrSubClustSClower, clustProbVents)\n",
    "\n",
    "    futureForecastsAdas[:, 2] = np.dot(predCurrSubClustSCupper, clustProbAdas)\n",
    "    futureForecastsVents[:, 2] = np.dot(predCurrSubClustSCupper, clustProbVents)\n",
    "\n",
    "    return futureForecastsAdas, futureForecastsVents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 16;\n",
       "            var nbb_formatted_code = \"def calcDpsGivenAges(ageAtPredDates, subShiftsCurr):\\n\\n    subShiftsPredDates = np.tile(subShiftsCurr, (ageAtPredDates.shape[0], 1))\\n\\n    # print('subShiftsPredDates', subShiftsPredDates.shape)\\n    # print('ageAtPredDates', ageAtPredDates.shape)\\n    assert subShiftsPredDates.shape[0] == ageAtPredDates.shape[0]\\n    assert subShiftsPredDates.shape[1] == 2\\n\\n    dpsPredCurr = VoxelDPM.calcDpsNo1array(subShiftsPredDates, ageAtPredDates)\\n\\n    return dpsPredCurr\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calcDpsGivenAges(ageAtPredDates, subShiftsCurr):\n",
    "\n",
    "    subShiftsPredDates = np.tile(subShiftsCurr, (ageAtPredDates.shape[0], 1))\n",
    "\n",
    "    # print('subShiftsPredDates', subShiftsPredDates.shape)\n",
    "    # print('ageAtPredDates', ageAtPredDates.shape)\n",
    "    assert subShiftsPredDates.shape[0] == ageAtPredDates.shape[0]\n",
    "    assert subShiftsPredDates.shape[1] == 2\n",
    "\n",
    "    dpsPredCurr = VoxelDPM.calcDpsNo1array(subShiftsPredDates, ageAtPredDates)\n",
    "\n",
    "    return dpsPredCurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 17;\n",
       "            var nbb_formatted_code = \"def addSubjIntercept(dpsT, futurePredictions, dataCurrSubjT, modelPredExistingVisits):\\n\\n    if np.isnan(dataCurrSubjT).all():\\n\\n        # no data available cur current subject, leave as population estimate\\n        return futurePredictions\\n    else:\\n        # data is\\n        return futurePredictions + (\\n            np.nanmean(dataCurrSubjT) - np.mean(modelPredExistingVisits)\\n        )\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def addSubjIntercept(dpsT, futurePredictions, dataCurrSubjT, modelPredExistingVisits):\n",
    "\n",
    "    if np.isnan(dataCurrSubjT).all():\n",
    "\n",
    "        # no data available cur current subject, leave as population estimate\n",
    "        return futurePredictions\n",
    "    else:\n",
    "        # data is\n",
    "        return futurePredictions + (\n",
    "            np.nanmean(dataCurrSubjT) - np.mean(modelPredExistingVisits)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 18;\n",
       "            var nbb_formatted_code = \"def writeTadpoleSubmission(\\n    predAdasAllSubj,\\n    predVentsAllSubj,\\n    predDiagAllSubj,\\n    outputFile,\\n    nrMonthsToPred,\\n    predStartDate,\\n    params,\\n):\\n\\n    predInd = params[\\\"predInd\\\"]\\n    predSetRidUnq = np.unique(predInd)\\n    print(\\\"Writing forecast to file %s\\\" % outputFile)\\n    submission_table = pd.DataFrame()\\n    nrSubjPredSet = predSetRidUnq.shape[0]\\n    # * Repeated matrices - compare with submission template\\n    submission_table[\\\"RID\\\"] = predSetRidUnq.repeat(nrMonthsToPred)\\n    submission_table[\\\"Forecast Month\\\"] = np.tile(\\n        range(1, nrMonthsToPred + 1), (nrSubjPredSet, 1)\\n    ).flatten()\\n\\n    from dateutil.relativedelta import relativedelta\\n\\n    endDate = predStartDate + relativedelta(months=+nrMonthsToPred - 1)\\n    ForecastDates = [predStartDate]\\n    while ForecastDates[-1] < endDate:\\n        ForecastDates.append(ForecastDates[-1] + relativedelta(months=+1))\\n\\n    ForecastDatesStrings = [\\n        datetime.datetime.strftime(d, \\\"%Y-%m\\\") for d in ForecastDates\\n    ]\\n    submission_table[\\\"Forecast Date\\\"] = np.tile(\\n        ForecastDatesStrings, (nrSubjPredSet, 1)\\n    ).flatten()\\n    # * Pre-fill forecast data, encoding missing data as NaN\\n    nanColumn = np.repeat(np.nan, submission_table.shape[0])\\n    submission_table[\\\"CN relative probability\\\"] = nanColumn\\n    submission_table[\\\"MCI relative probability\\\"] = nanColumn\\n    submission_table[\\\"AD relative probability\\\"] = nanColumn\\n    submission_table[\\\"ADAS13\\\"] = nanColumn\\n    submission_table[\\\"ADAS13 50% CI lower\\\"] = nanColumn\\n    submission_table[\\\"ADAS13 50% CI upper\\\"] = nanColumn\\n    submission_table[\\\"Ventricles_ICV\\\"] = nanColumn\\n    submission_table[\\\"Ventricles_ICV 50% CI lower\\\"] = nanColumn\\n    submission_table[\\\"Ventricles_ICV 50% CI upper\\\"] = nanColumn\\n\\n    # *** Paste in month-by-month forecasts **\\n    # * 1. Clinical status\\n    submission_table[\\\"CN relative probability\\\"] = predDiagAllSubj[:, :, 0].flatten()\\n    submission_table[\\\"MCI relative probability\\\"] = predDiagAllSubj[:, :, 1].flatten()\\n    submission_table[\\\"AD relative probability\\\"] = predDiagAllSubj[:, :, 2].flatten()\\n    # * 2. ADAS13 score\\n    submission_table[\\\"ADAS13\\\"] = predAdasAllSubj[:, :, 0].flatten()\\n    submission_table[\\\"ADAS13 50% CI lower\\\"] = predAdasAllSubj[:, :, 1].flatten()\\n    submission_table[\\\"ADAS13 50% CI upper\\\"] = predAdasAllSubj[:, :, 2].flatten()\\n    # * 3. Ventricles volume (normalised by intracranial volume)\\n    submission_table[\\\"Ventricles_ICV\\\"] = predVentsAllSubj[:, :, 0].flatten()\\n    submission_table[\\\"Ventricles_ICV 50% CI lower\\\"] = predVentsAllSubj[\\n        :, :, 1\\n    ].flatten()\\n    submission_table[\\\"Ventricles_ICV 50% CI upper\\\"] = predVentsAllSubj[\\n        :, :, 2\\n    ].flatten()\\n\\n    submission_table.to_csv(outputFile, index=False)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def writeTadpoleSubmission(\n",
    "    predAdasAllSubj,\n",
    "    predVentsAllSubj,\n",
    "    predDiagAllSubj,\n",
    "    outputFile,\n",
    "    nrMonthsToPred,\n",
    "    predStartDate,\n",
    "    params,\n",
    "):\n",
    "\n",
    "    predInd = params[\"predInd\"]\n",
    "    predSetRidUnq = np.unique(predInd)\n",
    "    print(\"Writing forecast to file %s\" % outputFile)\n",
    "    submission_table = pd.DataFrame()\n",
    "    nrSubjPredSet = predSetRidUnq.shape[0]\n",
    "    # * Repeated matrices - compare with submission template\n",
    "    submission_table[\"RID\"] = predSetRidUnq.repeat(nrMonthsToPred)\n",
    "    submission_table[\"Forecast Month\"] = np.tile(\n",
    "        range(1, nrMonthsToPred + 1), (nrSubjPredSet, 1)\n",
    "    ).flatten()\n",
    "\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    endDate = predStartDate + relativedelta(months=+nrMonthsToPred - 1)\n",
    "    ForecastDates = [predStartDate]\n",
    "    while ForecastDates[-1] < endDate:\n",
    "        ForecastDates.append(ForecastDates[-1] + relativedelta(months=+1))\n",
    "\n",
    "    ForecastDatesStrings = [\n",
    "        datetime.datetime.strftime(d, \"%Y-%m\") for d in ForecastDates\n",
    "    ]\n",
    "    submission_table[\"Forecast Date\"] = np.tile(\n",
    "        ForecastDatesStrings, (nrSubjPredSet, 1)\n",
    "    ).flatten()\n",
    "    # * Pre-fill forecast data, encoding missing data as NaN\n",
    "    nanColumn = np.repeat(np.nan, submission_table.shape[0])\n",
    "    submission_table[\"CN relative probability\"] = nanColumn\n",
    "    submission_table[\"MCI relative probability\"] = nanColumn\n",
    "    submission_table[\"AD relative probability\"] = nanColumn\n",
    "    submission_table[\"ADAS13\"] = nanColumn\n",
    "    submission_table[\"ADAS13 50% CI lower\"] = nanColumn\n",
    "    submission_table[\"ADAS13 50% CI upper\"] = nanColumn\n",
    "    submission_table[\"Ventricles_ICV\"] = nanColumn\n",
    "    submission_table[\"Ventricles_ICV 50% CI lower\"] = nanColumn\n",
    "    submission_table[\"Ventricles_ICV 50% CI upper\"] = nanColumn\n",
    "\n",
    "    # *** Paste in month-by-month forecasts **\n",
    "    # * 1. Clinical status\n",
    "    submission_table[\"CN relative probability\"] = predDiagAllSubj[:, :, 0].flatten()\n",
    "    submission_table[\"MCI relative probability\"] = predDiagAllSubj[:, :, 1].flatten()\n",
    "    submission_table[\"AD relative probability\"] = predDiagAllSubj[:, :, 2].flatten()\n",
    "    # * 2. ADAS13 score\n",
    "    submission_table[\"ADAS13\"] = predAdasAllSubj[:, :, 0].flatten()\n",
    "    submission_table[\"ADAS13 50% CI lower\"] = predAdasAllSubj[:, :, 1].flatten()\n",
    "    submission_table[\"ADAS13 50% CI upper\"] = predAdasAllSubj[:, :, 2].flatten()\n",
    "    # * 3. Ventricles volume (normalised by intracranial volume)\n",
    "    submission_table[\"Ventricles_ICV\"] = predVentsAllSubj[:, :, 0].flatten()\n",
    "    submission_table[\"Ventricles_ICV 50% CI lower\"] = predVentsAllSubj[\n",
    "        :, :, 1\n",
    "    ].flatten()\n",
    "    submission_table[\"Ventricles_ICV 50% CI upper\"] = predVentsAllSubj[\n",
    "        :, :, 2\n",
    "    ].flatten()\n",
    "\n",
    "    submission_table.to_csv(outputFile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 19;\n",
       "            var nbb_formatted_code = \"def runAllExpTADPOLE(params, expName, dpmBuilder):\\n    \\\"\\\"\\\" runs all experiments\\\"\\\"\\\"\\n\\n    res = {}\\n\\n    params[\\\"patientID\\\"] = AD\\n    params[\\\"excludeID\\\"] = -1\\n    params[\\\"excludeXvalidID\\\"] = []\\n    params[\\\"excludeStaging\\\"] = [-1]\\n    params[\\\"anchorID\\\"] = MCI\\n\\n    # run if this is the master   process or nrProcesses is 1\\n    unluckyProc = (\\n        np.mod(params[\\\"currModel\\\"] - 1, params[\\\"nrProcesses\\\"]) == params[\\\"runIndex\\\"] - 1\\n    )\\n    unluckyOrNoParallel = (\\n        unluckyProc or (params[\\\"nrProcesses\\\"] == 1) or params[\\\"masterProcess\\\"]\\n    )\\n\\n    if unluckyOrNoParallel:\\n        dpmObj, res[\\\"std\\\"] = evaluationFramework.runStdDPM(\\n            params, expName, dpmBuilder, params[\\\"runPartMain\\\"]\\n        )\\n\\n    return res\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def runAllExpTADPOLE(params, expName, dpmBuilder):\n",
    "    \"\"\" runs all experiments\"\"\"\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    params[\"patientID\"] = AD\n",
    "    params[\"excludeID\"] = -1\n",
    "    params[\"excludeXvalidID\"] = []\n",
    "    params[\"excludeStaging\"] = [-1]\n",
    "    params[\"anchorID\"] = MCI\n",
    "\n",
    "    # run if this is the master   process or nrProcesses is 1\n",
    "    unluckyProc = (\n",
    "        np.mod(params[\"currModel\"] - 1, params[\"nrProcesses\"]) == params[\"runIndex\"] - 1\n",
    "    )\n",
    "    unluckyOrNoParallel = (\n",
    "        unluckyProc or (params[\"nrProcesses\"] == 1) or params[\"masterProcess\"]\n",
    "    )\n",
    "\n",
    "    if unluckyOrNoParallel:\n",
    "        dpmObj, res[\"std\"] = evaluationFramework.runStdDPM(\n",
    "            params, expName, dpmBuilder, params[\"runPartMain\"]\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dive_tadpole/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n",
      "/anaconda3/envs/dive_tadpole/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1628: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "/anaconda3/envs/dive_tadpole/lib/python3.7/site-packages/ipykernel_launcher.py:118: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partCode [   2    3    3 ... 4557 4512 2380]\n",
      "filtPartCode [   2    3    3 ... 4557 4512 2380]\n",
      "longPartCode [   2    3    4 ... 5294 5295 5296]\n",
      "inverseMap [   0    1    1 ... 1310 1282  935]\n",
      "np.max(inverseMap) 1736\n",
      "len(longData) 1737\n",
      "11984 1736 1737 11984\n",
      "crossDiag 0 [1. 3. 3. ... 2. 2. 2.]\n",
      "minMaxRange (12,)\n",
      "clustProbBCColNorm (12, 12)\n",
      "crossDiag [1. 3. 3. ... 2. 2. 2.] patientID 3\n",
      "extraRangeFactor 1.0\n",
      "outerIt  0\n",
      "innerIt  0\n",
      "disprogscore c= 8\n",
      "disprogscore c= 9\n",
      "disprogscore c= 10\n",
      "disprogscore c= 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pushpanjali/TADPOLE-SHARE/jupyter/notebooks/DIVE-TADPOLE/PlotterVDPM.py:1793: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n",
      "/Users/pushpanjali/TADPOLE-SHARE/jupyter/notebooks/DIVE-TADPOLE/PlotterVDPM.py:1797: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  pl.pause(0.05)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate subject shifts\n"
     ]
    }
   ],
   "source": [
    "def printResADNIthick(modelNames, res, plotTrajParams):\n",
    "    # nrModels = len(modelNames)\n",
    "\n",
    "    # dinamicModelName = 'VWDPMLinear'\n",
    "    # staticModelName = 'VWDPMLinearStatic'\n",
    "    # dinamicModelName = 'VDPM_MRF'\n",
    "    # staticModelName = 'VWDPMStatic'\n",
    "    # noDPSModelName = 'VDPMNoDPS'\n",
    "\n",
    "    print(\"##### biomk prediction ######\")\n",
    "    nrModels = len(modelNames)\n",
    "    pred = list(range(nrModels))\n",
    "    predMean = list(range(nrModels))\n",
    "    predStd = list(range(nrModels))\n",
    "    for m in range(nrModels):\n",
    "        pred[m] = res[m][\"cogCorr\"][\"predStats\"]\n",
    "        predMean[m] = np.nanmean(pred[m])\n",
    "        predStd[m] = np.nanstd(pred[m])\n",
    "\n",
    "    for m in range(nrModels):\n",
    "        print(\"%s predAllFolds\" % modelNames[m], pred[m])\n",
    "    for m in range(nrModels):\n",
    "        print(\"%s predMean\" % modelNames[m], predMean[m])\n",
    "    for m in range(nrModels):\n",
    "        print(\"%s predStd\" % modelNames[m], predStd[m])\n",
    "\n",
    "    stats = list(range(nrModels))\n",
    "    print(\"##### correlation with cog tests ######\")\n",
    "    for m in range(nrModels):\n",
    "        stats[m] = res[m][\"cogCorr\"][\n",
    "            \"statsAllFolds\"\n",
    "        ]  # shape (NR_FOLDS, 2*NR_COG_TESTS)\n",
    "        # print('stats:', stats[m])\n",
    "        print(modelNames[m], end=\"\")\n",
    "        meanStats = np.nanmean(stats[m], 0)\n",
    "        stdStats = np.nanstd(stats[m], 0)\n",
    "        for i in range(meanStats.shape[0]):\n",
    "            print(\"%.2f +/- %.2f\" % (meanStats[i], stdStats[i]), end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "    plotScoresHist(scores=pred, labels=modelNames)\n",
    "\n",
    "    nrCogStats = stats[0].shape[1]\n",
    "\n",
    "    # perform paired t-test, as the same cross-validation folds have been used in both cases\n",
    "    tStats = np.zeros(nrCogStats, float)\n",
    "    pVals = np.zeros(nrCogStats, float)\n",
    "    for t in range(nrCogStats):\n",
    "        tStats[t], pVals[t] = scipy.stats.ttest_rel(stats[0][:, t], stats[0][:, t])\n",
    "\n",
    "    # expInds = [dinIndex, staIndex, noDPSIndex]\n",
    "    # printDiffs(expInds, res, modelNames)\n",
    "\n",
    "    # testPredFPBDin = res[dinIndex]['cogCorr']['testPredPredFPB']\n",
    "    # testPredFPBSta = res[staIndex]['cogCorr']['testPredPredFPB']\n",
    "    # testPredFPBNoDPS = res[noDPSIndex]['cogCorr']['testPredPredFPB']\n",
    "    # testPredDataFPB = res[noDPSIndex]['cogCorr']['testPredDataFPB']\n",
    "    #\n",
    "    # outDir = 'resfiles/%s' % plotTrajParams['expName']\n",
    "    # os.system('mkdir -p %s' % outDir)\n",
    "    #\n",
    "    # for i in [0]: #range(len(testPredFPBDin)):\n",
    "    #   print('testPred diff [%d] ' % i, testPredFPBDin[i] - testPredFPBSta[i])\n",
    "    #\n",
    "    #   meanAbsDiffB = np.sum(np.abs(testPredFPBDin[i] - testPredFPBSta[i]), axis=0)\n",
    "    #   plotter = PlotterVDPM.PlotterVDPM()\n",
    "    #   plotter.plotDiffs(meanAbsDiffB, plotTrajParams,\n",
    "    #     filePathNoExt='%s/diffPredDinSta_f%d' % (outDir, i))\n",
    "\n",
    "\n",
    "# def printDiffs(expInds, res, modelNames):\n",
    "#\n",
    "#   for ind in range(len(expInds)):\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # model 4 - VDPM sigmoidal\n",
    "    # model 5 - VDPM linear\n",
    "\n",
    "    if args.get(\"modelToRun\"):\n",
    "        modelToRun = args.get(\"modelToRun\")\n",
    "    elif args.get(\"models\"):\n",
    "        modelToRun = np.array(args.get(\"models\"))\n",
    "    else:\n",
    "        raise ValueError(\"need to set either --models or --firstModel & --lastModel\")\n",
    "\n",
    "    launchTadpole(args.get(\"runIndex\"), args.get(\"nrProc\"), modelToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
